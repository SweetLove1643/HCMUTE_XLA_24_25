import os
import streamlit as st
import numpy as np
import cv2
from ultralytics import YOLO

def FruitRecognization():
    # ƒê∆∞·ªùng d·∫´n model PT
    model_path = "fruitRecognizationModel.pt"

    # Danh s√°ch t√™n l·ªõp
    class_names = ['sau_rieng', 'tao', 'thanh_long', 'MangCut', 'Chuoi']

    # Ng∆∞·ª°ng confidence v√† IoU
    CONF_THRESHOLD = 0.5
    IOU_THRESHOLD = 0.4

    # Ti√™u ƒë·ªÅ ·ª©ng d·ª•ng
    st.title('üçé Nh·∫≠n d·∫°ng tr√°i c√¢y v·ªõi YOLOv8')

    # Load model n·∫øu ch∆∞a c√≥
    if "LoadModel" not in st.session_state:
        st.session_state["Model"] = YOLO(model_path)
        st.session_state["LoadModel"] = True
        print('‚ö° Load model l·∫ßn ƒë·∫ßu')
    else:
        print('‚úÖ Model ƒë√£ ƒë∆∞·ª£c load tr∆∞·ªõc ƒë√≥')

    # H√†m hi·ªÉn th·ªã k·∫øt qu·∫£
    def display_results(img, results):
        output_img = img.copy()
        boxes = results.boxes.xyxy.cpu().numpy() if hasattr(results.boxes, 'xyxy') else []
        confs = results.boxes.conf.cpu().numpy() if hasattr(results.boxes, 'conf') else []
        cls_ids = results.boxes.cls.cpu().numpy().astype(int) if hasattr(results.boxes, 'cls') else []

        for i, box in enumerate(boxes):
            x1, y1, x2, y2 = map(int, box)
            cls_id = cls_ids[i]
            conf = confs[i]
            cls_name = class_names[cls_id] if cls_id < len(class_names) else f"Class {cls_id}"

            cv2.rectangle(output_img, (x1, y1), (x2, y2), (0, 255, 0), 2)
            label = f"{cls_name}: {conf:.2f}"

            (label_width, label_height), baseline = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)
            cv2.rectangle(output_img, (x1, y1 - label_height - baseline), (x1 + label_width, y1), (255, 255, 255), cv2.FILLED)
            cv2.putText(output_img, label, (x1, y1 - baseline), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1)

        return output_img

    # Giao di·ªán ch√≠nh
    st.header("üì∑ Nh·∫≠n d·∫°ng t·ª´ ·∫£nh")

    # Upload ·∫£nh
    st.subheader("üì§ T·∫£i ·∫£nh l√™n")
    img_file_buffer = st.file_uploader("Ch·ªçn ·∫£nh", type=["jpg", "jpeg", "png", "bmp"])
    img_array = None

    if img_file_buffer is not None:
        nparr = np.frombuffer(img_file_buffer.read(), np.uint8)
        img_array = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        display_img = cv2.cvtColor(img_array, cv2.COLOR_BGR2RGB)
        st.image(display_img, caption="·∫¢nh ƒë√£ t·∫£i l√™n", use_container_width=True)

    # N√∫t nh·∫≠n d·∫°ng
    if img_array is not None and st.button('üîç Nh·∫≠n d·∫°ng tr√°i c√¢y'):
        with st.spinner('‚è≥ ƒêang nh·∫≠n d·∫°ng...'):
            results = st.session_state["Model"].predict(
                source=img_array,
                conf=CONF_THRESHOLD,
                iou=IOU_THRESHOLD,
                verbose=False
            )[0]

            processed_img = display_results(img_array, results)
            detection_count = len(results.boxes)

            processed_img_rgb = cv2.cvtColor(processed_img, cv2.COLOR_BGR2RGB)
            st.success(f"‚úÖ ƒê√£ ph√°t hi·ªán {detection_count} ƒë·ªëi t∆∞·ª£ng.")
            st.image(processed_img_rgb, caption="üìç K·∫øt qu·∫£ nh·∫≠n d·∫°ng", use_container_width=True)

            # Chi ti·∫øt nh·∫≠n d·∫°ng
            if detection_count > 0:
                st.subheader("üìã Chi ti·∫øt nh·∫≠n d·∫°ng")
                data = []
                boxes = results.boxes.xyxy.cpu().numpy()
                confs = results.boxes.conf.cpu().numpy()
                cls_ids = results.boxes.cls.cpu().numpy().astype(int)

                for i in range(detection_count):
                    cls_id = cls_ids[i]
                    cls_name = class_names[cls_id] if cls_id < len(class_names) else f"Lo·∫°i {cls_id}"
                    conf = confs[i]
                    data.append({"Lo·∫°i tr√°i c√¢y": cls_name, "ƒê·ªô tin c·∫≠y": f"{conf:.4f}"})

                st.table(data)
