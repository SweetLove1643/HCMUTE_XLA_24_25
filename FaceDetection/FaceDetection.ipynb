{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da204d86",
   "metadata": {},
   "source": [
    "## Tăng cường dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0364c9c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\albumentations\\core\\validation.py:111: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
      "  original_init(self, **validated_kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã tạo 800 ảnh tăng cường.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import albumentations as A\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Thư mục chứa 5 ảnh gốc và thư mục lưu ảnh tăng cường\n",
    "input_dir = \"input_images\"  # 5 ảnh gốc: person1.jpg, person2.jpg, ..., person5.jpg\n",
    "output_dir = \"augmented_images\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# # Định nghĩa pipeline tăng cường dữ liệu\n",
    "# transform = A.Compose([\n",
    "#     A.Rotate(limit=30, p=0.5),  # Xoay ngẫu nhiên ±30 độ\n",
    "#     A.HorizontalFlip(p=0.5),  # Lật ngang\n",
    "#     A.RandomBrightnessContrast(p=0.5),  # Thay đổi độ sáng/tương phản\n",
    "#     A.GaussNoise(p=0.3),  # Thêm nhiễu\n",
    "#     A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=15, p=0.5),\n",
    "#     A.Resize(height=224, width=224),  # Resize về kích thước thống nhất\n",
    "# ])\n",
    "# Pipeline tăng cường dữ liệu hoàn chỉnh và hiệu quả\n",
    "\n",
    "transform = A.Compose([\n",
    "    # Biến đổi hình học nâng cao\n",
    "    A.OneOf([\n",
    "        A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=15),\n",
    "        A.Affine(shear=15),\n",
    "        A.Perspective(scale=(0.05, 0.1)),\n",
    "    ], p=0.7),\n",
    "\n",
    "    # Xoay nhẹ (giữ lại từ pipeline gốc)\n",
    "    A.Rotate(limit=30, p=0.5),\n",
    "\n",
    "    # Lật ngang + dọc\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.1),\n",
    "\n",
    "    # Biến đổi ánh sáng và màu sắc\n",
    "    A.OneOf([\n",
    "        A.RandomBrightnessContrast(p=1.0),\n",
    "        A.CLAHE(p=1.0),\n",
    "        A.HueSaturationValue(p=1.0),\n",
    "    ], p=0.7),\n",
    "\n",
    "    # Nhiễu và kênh ảnh\n",
    "    A.OneOf([\n",
    "        A.GaussNoise(p=1.0),\n",
    "        A.ISONoise(p=1.0),\n",
    "    ], p=0.2),\n",
    "\n",
    "    A.OneOf([\n",
    "        A.RGBShift(p=1.0),\n",
    "        A.ChannelShuffle(p=1.0),\n",
    "        A.ToGray(p=1.0),\n",
    "    ], p=0.3),\n",
    "\n",
    "    # Resize và chuẩn hóa\n",
    "    A.Resize(height=224, width=224)\n",
    "])\n",
    "\n",
    "\n",
    "# Danh sách người và nhãn\n",
    "people = [\"QuanPhan\", \"DangDuong\", \"ManhTuong\", \"HuuTho\"]\n",
    "\n",
    "# Tăng cường dữ liệu\n",
    "num_augmented_per_image = 200  # Mỗi ảnh gốc tạo 200 ảnh mới\n",
    "for person in people:\n",
    "    img_path = os.path.join(input_dir, f\"{person}.jpg\")\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Chuyển sang RGB\n",
    "    \n",
    "    # Tạo thư mục cho mỗi người\n",
    "    person_dir = os.path.join(output_dir, person)\n",
    "    os.makedirs(person_dir, exist_ok=True)\n",
    "    \n",
    "    # Tạo ảnh tăng cường\n",
    "    for i in range(num_augmented_per_image):\n",
    "        augmented = transform(image=img)[\"image\"]\n",
    "        save_path = os.path.join(person_dir, f\"{person}_aug_{i}.jpg\")\n",
    "        cv2.imwrite(save_path, cv2.cvtColor(augmented, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "print(f\"Đã tạo {num_augmented_per_image * len(people)} ảnh tăng cường.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5cebc414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Person QuanPhan:\n",
      "  Train: 140 images\n",
      "  Val: 30 images\n",
      "  Test: 30 images\n",
      "Person DangDuong:\n",
      "  Train: 140 images\n",
      "  Val: 30 images\n",
      "  Test: 30 images\n",
      "Person ManhTuong:\n",
      "  Train: 140 images\n",
      "  Val: 30 images\n",
      "  Test: 30 images\n",
      "Person HuuTho:\n",
      "  Train: 140 images\n",
      "  Val: 30 images\n",
      "  Test: 30 images\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "# Thư mục chứa ảnh tăng cường và thư mục đầu ra\n",
    "augmented_dir = \"augmented_images\"\n",
    "output_base_dir = \"dataset\"\n",
    "train_dir = os.path.join(output_base_dir, \"train\")\n",
    "val_dir = os.path.join(output_base_dir, \"val\")\n",
    "test_dir = os.path.join(output_base_dir, \"test\")\n",
    "\n",
    "# Tỷ lệ chia tập\n",
    "train_ratio = 0.7  # 70% cho train\n",
    "val_ratio = 0.15   # 15% cho validation\n",
    "test_ratio = 0.15  # 15% cho test\n",
    "\n",
    "# Danh sách người\n",
    "people = [\"QuanPhan\", \"DangDuong\", \"ManhTuong\", \"HuuTho\"]\n",
    "\n",
    "# Tạo thư mục train, val, test\n",
    "for split_dir in [train_dir, val_dir, test_dir]:\n",
    "    for person in people:\n",
    "        os.makedirs(os.path.join(split_dir, person), exist_ok=True)\n",
    "\n",
    "# Hàm chia dữ liệu\n",
    "for person in people:\n",
    "    # Lấy danh sách tất cả ảnh của person\n",
    "    person_dir = os.path.join(augmented_dir, person)\n",
    "    images = [f for f in os.listdir(person_dir) if f.endswith(\".jpg\")]\n",
    "    random.shuffle(images)  # Xáo trộn ngẫu nhiên\n",
    "\n",
    "    # Tính số lượng ảnh cho từng tập\n",
    "    total_images = len(images)\n",
    "    train_count = int(total_images * train_ratio)\n",
    "    val_count = int(total_images * val_ratio)\n",
    "    test_count = total_images - train_count - val_count  # Đảm bảo tổng = 100%\n",
    "\n",
    "    # Chia danh sách ảnh\n",
    "    train_images = images[:train_count]\n",
    "    val_images = images[train_count:train_count + val_count]\n",
    "    test_images = images[train_count + val_count:]\n",
    "\n",
    "    # Sao chép ảnh vào các thư mục tương ứng\n",
    "    for img in train_images:\n",
    "        shutil.copy(os.path.join(person_dir, img), os.path.join(train_dir, person, img))\n",
    "    for img in val_images:\n",
    "        shutil.copy(os.path.join(person_dir, img), os.path.join(val_dir, person, img))\n",
    "    for img in test_images:\n",
    "        shutil.copy(os.path.join(person_dir, img), os.path.join(test_dir, person, img))\n",
    "\n",
    "    print(f\"Person {person}:\")\n",
    "    print(f\"  Train: {len(train_images)} images\")\n",
    "    print(f\"  Val: {len(val_images)} images\")\n",
    "    print(f\"  Test: {len(test_images)} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee010ca5",
   "metadata": {},
   "source": [
    "# Huấn luyện"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27ae8fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From f:\\Study\\Projects\\HK6\\XLA\\.venv\\Lib\\site-packages\\tf2onnx\\tf_loader.py:68: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From f:\\Study\\Projects\\HK6\\XLA\\.venv\\Lib\\site-packages\\tf2onnx\\tf_loader.py:72: The name tf.train.import_meta_graph is deprecated. Please use tf.compat.v1.train.import_meta_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
    "import matplotlib.pyplot as plt\n",
    "import onnxruntime as ort\n",
    "import os\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import tf2onnx\n",
    "import onnx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37d8b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 560 images belonging to 4 classes.\n",
      "Found 120 images belonging to 4 classes.\n",
      "Found 120 images belonging to 5 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Study\\Projects\\HK6\\XLA\\.venv\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.3005 - loss: 1.4455 - precision: 0.3684 - recall: 0.0889"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Study\\Projects\\HK6\\XLA\\.venv\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.80000, saving model to best_vgg_face.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 7s/step - accuracy: 0.3053 - loss: 1.4395 - precision: 0.3745 - recall: 0.0900 - val_accuracy: 0.8000 - val_loss: 0.9525 - val_precision: 1.0000 - val_recall: 0.1250 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.7003 - loss: 0.9205 - precision: 0.8853 - recall: 0.3866\n",
      "Epoch 2: val_accuracy improved from 0.80000 to 0.90833, saving model to best_vgg_face.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 7s/step - accuracy: 0.7028 - loss: 0.9162 - precision: 0.8865 - recall: 0.3904 - val_accuracy: 0.9083 - val_loss: 0.6411 - val_precision: 1.0000 - val_recall: 0.7333 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.8191 - loss: 0.6358 - precision: 0.9290 - recall: 0.6507\n",
      "Epoch 3: val_accuracy improved from 0.90833 to 0.92500, saving model to best_vgg_face.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 6s/step - accuracy: 0.8201 - loss: 0.6342 - precision: 0.9299 - recall: 0.6526 - val_accuracy: 0.9250 - val_loss: 0.4518 - val_precision: 1.0000 - val_recall: 0.8500 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9028 - loss: 0.4837 - precision: 0.9777 - recall: 0.7583\n",
      "Epoch 4: val_accuracy improved from 0.92500 to 0.95833, saving model to best_vgg_face.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 7s/step - accuracy: 0.9032 - loss: 0.4816 - precision: 0.9780 - recall: 0.7600 - val_accuracy: 0.9583 - val_loss: 0.3111 - val_precision: 1.0000 - val_recall: 0.9083 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.9175 - loss: 0.3615 - precision: 0.9713 - recall: 0.8573\n",
      "Epoch 5: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 7s/step - accuracy: 0.9180 - loss: 0.3605 - precision: 0.9712 - recall: 0.8575 - val_accuracy: 0.9583 - val_loss: 0.2405 - val_precision: 1.0000 - val_recall: 0.9333 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.9559 - loss: 0.2621 - precision: 0.9800 - recall: 0.9094\n",
      "Epoch 6: val_accuracy improved from 0.95833 to 0.97500, saving model to best_vgg_face.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 7s/step - accuracy: 0.9550 - loss: 0.2629 - precision: 0.9801 - recall: 0.9087 - val_accuracy: 0.9750 - val_loss: 0.1942 - val_precision: 0.9912 - val_recall: 0.9333 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9761 - loss: 0.2257 - precision: 0.9895 - recall: 0.9263\n",
      "Epoch 7: val_accuracy did not improve from 0.97500\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 7s/step - accuracy: 0.9761 - loss: 0.2246 - precision: 0.9896 - recall: 0.9271 - val_accuracy: 0.9667 - val_loss: 0.1697 - val_precision: 0.9912 - val_recall: 0.9417 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9872 - loss: 0.1677 - precision: 0.9948 - recall: 0.9526\n",
      "Epoch 8: val_accuracy improved from 0.97500 to 0.99167, saving model to best_vgg_face.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 7s/step - accuracy: 0.9870 - loss: 0.1676 - precision: 0.9947 - recall: 0.9526 - val_accuracy: 0.9917 - val_loss: 0.1284 - val_precision: 1.0000 - val_recall: 0.9667 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9785 - loss: 0.1485 - precision: 0.9917 - recall: 0.9715\n",
      "Epoch 9: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 6s/step - accuracy: 0.9784 - loss: 0.1482 - precision: 0.9915 - recall: 0.9713 - val_accuracy: 0.9917 - val_loss: 0.1140 - val_precision: 1.0000 - val_recall: 0.9833 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9656 - loss: 0.1509 - precision: 0.9837 - recall: 0.9475\n",
      "Epoch 10: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 6s/step - accuracy: 0.9653 - loss: 0.1512 - precision: 0.9836 - recall: 0.9472 - val_accuracy: 0.9917 - val_loss: 0.0930 - val_precision: 1.0000 - val_recall: 0.9833 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9669 - loss: 0.1428 - precision: 0.9833 - recall: 0.9446\n",
      "Epoch 11: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 6s/step - accuracy: 0.9674 - loss: 0.1421 - precision: 0.9836 - recall: 0.9452 - val_accuracy: 0.9917 - val_loss: 0.0911 - val_precision: 0.9915 - val_recall: 0.9667 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9847 - loss: 0.1060 - precision: 0.9939 - recall: 0.9713\n",
      "Epoch 12: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 7s/step - accuracy: 0.9846 - loss: 0.1057 - precision: 0.9938 - recall: 0.9713 - val_accuracy: 0.9917 - val_loss: 0.0767 - val_precision: 0.9917 - val_recall: 0.9917 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9741 - loss: 0.1033 - precision: 0.9805 - recall: 0.9634\n",
      "Epoch 13: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 6s/step - accuracy: 0.9745 - loss: 0.1029 - precision: 0.9810 - recall: 0.9636 - val_accuracy: 0.9833 - val_loss: 0.0780 - val_precision: 0.9915 - val_recall: 0.9750 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9873 - loss: 0.0902 - precision: 0.9953 - recall: 0.9690\n",
      "Epoch 14: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 6s/step - accuracy: 0.9874 - loss: 0.0902 - precision: 0.9953 - recall: 0.9691 - val_accuracy: 0.9917 - val_loss: 0.0709 - val_precision: 0.9916 - val_recall: 0.9833 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9863 - loss: 0.0868 - precision: 0.9885 - recall: 0.9820\n",
      "Epoch 15: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 7s/step - accuracy: 0.9861 - loss: 0.0870 - precision: 0.9884 - recall: 0.9816 - val_accuracy: 0.9917 - val_loss: 0.0543 - val_precision: 1.0000 - val_recall: 0.9917 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9749 - loss: 0.0825 - precision: 0.9807 - recall: 0.9616\n",
      "Epoch 16: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 7s/step - accuracy: 0.9752 - loss: 0.0825 - precision: 0.9809 - recall: 0.9620 - val_accuracy: 0.9833 - val_loss: 0.0650 - val_precision: 1.0000 - val_recall: 0.9667 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9895 - loss: 0.0781 - precision: 0.9902 - recall: 0.9850\n",
      "Epoch 17: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 6s/step - accuracy: 0.9897 - loss: 0.0775 - precision: 0.9904 - recall: 0.9852 - val_accuracy: 0.9917 - val_loss: 0.0492 - val_precision: 0.9917 - val_recall: 0.9917 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9809 - loss: 0.0776 - precision: 0.9833 - recall: 0.9748\n",
      "Epoch 18: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 6s/step - accuracy: 0.9809 - loss: 0.0775 - precision: 0.9833 - recall: 0.9750 - val_accuracy: 0.9917 - val_loss: 0.0475 - val_precision: 0.9916 - val_recall: 0.9833 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9954 - loss: 0.0496 - precision: 0.9966 - recall: 0.9889\n",
      "Epoch 19: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 6s/step - accuracy: 0.9953 - loss: 0.0502 - precision: 0.9966 - recall: 0.9884 - val_accuracy: 0.9917 - val_loss: 0.0461 - val_precision: 0.9916 - val_recall: 0.9833 - learning_rate: 0.0010\n",
      "Epoch 20/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9755 - loss: 0.0649 - precision: 0.9897 - recall: 0.9731\n",
      "Epoch 20: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 6s/step - accuracy: 0.9759 - loss: 0.0645 - precision: 0.9900 - recall: 0.9735 - val_accuracy: 0.9917 - val_loss: 0.0413 - val_precision: 0.9917 - val_recall: 0.9917 - learning_rate: 0.0010\n",
      "Epoch 21/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9865 - loss: 0.0484 - precision: 0.9883 - recall: 0.9846\n",
      "Epoch 21: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 6s/step - accuracy: 0.9867 - loss: 0.0484 - precision: 0.9885 - recall: 0.9847 - val_accuracy: 0.9917 - val_loss: 0.0367 - val_precision: 1.0000 - val_recall: 0.9917 - learning_rate: 0.0010\n",
      "Epoch 22/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9864 - loss: 0.0594 - precision: 0.9863 - recall: 0.9834\n",
      "Epoch 22: val_accuracy improved from 0.99167 to 1.00000, saving model to best_vgg_face.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 7s/step - accuracy: 0.9864 - loss: 0.0596 - precision: 0.9864 - recall: 0.9833 - val_accuracy: 1.0000 - val_loss: 0.0341 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 0.0010\n",
      "Epoch 23/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9778 - loss: 0.0521 - precision: 0.9905 - recall: 0.9745\n",
      "Epoch 23: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 6s/step - accuracy: 0.9779 - loss: 0.0521 - precision: 0.9906 - recall: 0.9746 - val_accuracy: 0.9917 - val_loss: 0.0361 - val_precision: 1.0000 - val_recall: 0.9917 - learning_rate: 0.0010\n",
      "Epoch 24/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9800 - loss: 0.0655 - precision: 0.9819 - recall: 0.9775\n",
      "Epoch 24: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 6s/step - accuracy: 0.9804 - loss: 0.0649 - precision: 0.9823 - recall: 0.9779 - val_accuracy: 1.0000 - val_loss: 0.0370 - val_precision: 1.0000 - val_recall: 0.9917 - learning_rate: 0.0010\n",
      "Epoch 25/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9867 - loss: 0.0525 - precision: 0.9919 - recall: 0.9860\n",
      "Epoch 25: val_accuracy did not improve from 1.00000\n",
      "\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 6s/step - accuracy: 0.9869 - loss: 0.0524 - precision: 0.9921 - recall: 0.9861 - val_accuracy: 0.9917 - val_loss: 0.0348 - val_precision: 0.9917 - val_recall: 0.9917 - learning_rate: 0.0010\n",
      "Epoch 26/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9879 - loss: 0.0527 - precision: 0.9956 - recall: 0.9868\n",
      "Epoch 26: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 7s/step - accuracy: 0.9883 - loss: 0.0523 - precision: 0.9957 - recall: 0.9870 - val_accuracy: 1.0000 - val_loss: 0.0289 - val_precision: 1.0000 - val_recall: 0.9917 - learning_rate: 2.0000e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9906 - loss: 0.0392 - precision: 0.9908 - recall: 0.9905\n",
      "Epoch 27: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 6s/step - accuracy: 0.9906 - loss: 0.0392 - precision: 0.9909 - recall: 0.9904 - val_accuracy: 0.9917 - val_loss: 0.0303 - val_precision: 1.0000 - val_recall: 0.9917 - learning_rate: 2.0000e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9934 - loss: 0.0406 - precision: 0.9936 - recall: 0.9922\n",
      "Epoch 28: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 6s/step - accuracy: 0.9935 - loss: 0.0404 - precision: 0.9938 - recall: 0.9922 - val_accuracy: 1.0000 - val_loss: 0.0279 - val_precision: 1.0000 - val_recall: 0.9917 - learning_rate: 2.0000e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9957 - loss: 0.0320 - precision: 0.9957 - recall: 0.9957\n",
      "Epoch 29: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 6s/step - accuracy: 0.9957 - loss: 0.0321 - precision: 0.9957 - recall: 0.9957 - val_accuracy: 1.0000 - val_loss: 0.0270 - val_precision: 1.0000 - val_recall: 0.9917 - learning_rate: 2.0000e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9950 - loss: 0.0388 - precision: 0.9950 - recall: 0.9950\n",
      "Epoch 30: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 7s/step - accuracy: 0.9951 - loss: 0.0386 - precision: 0.9951 - recall: 0.9951 - val_accuracy: 0.9917 - val_loss: 0.0274 - val_precision: 1.0000 - val_recall: 0.9917 - learning_rate: 2.0000e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9953 - loss: 0.0301 - precision: 0.9953 - recall: 0.9953\n",
      "Epoch 31: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 7s/step - accuracy: 0.9954 - loss: 0.0302 - precision: 0.9954 - recall: 0.9954 - val_accuracy: 1.0000 - val_loss: 0.0266 - val_precision: 1.0000 - val_recall: 0.9917 - learning_rate: 2.0000e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9907 - loss: 0.0388 - precision: 0.9933 - recall: 0.9907\n",
      "Epoch 32: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 6s/step - accuracy: 0.9910 - loss: 0.0385 - precision: 0.9936 - recall: 0.9910 - val_accuracy: 1.0000 - val_loss: 0.0266 - val_precision: 1.0000 - val_recall: 0.9917 - learning_rate: 2.0000e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9911 - loss: 0.0368 - precision: 0.9911 - recall: 0.9887\n",
      "Epoch 33: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 6s/step - accuracy: 0.9911 - loss: 0.0369 - precision: 0.9911 - recall: 0.9886 - val_accuracy: 1.0000 - val_loss: 0.0261 - val_precision: 1.0000 - val_recall: 1.0000 - learning_rate: 2.0000e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9905 - loss: 0.0464 - precision: 0.9905 - recall: 0.9905\n",
      "Epoch 34: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 6s/step - accuracy: 0.9908 - loss: 0.0460 - precision: 0.9908 - recall: 0.9908 - val_accuracy: 1.0000 - val_loss: 0.0274 - val_precision: 1.0000 - val_recall: 0.9917 - learning_rate: 2.0000e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9904 - loss: 0.0405 - precision: 0.9904 - recall: 0.9901\n",
      "Epoch 35: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 6s/step - accuracy: 0.9905 - loss: 0.0404 - precision: 0.9905 - recall: 0.9901 - val_accuracy: 1.0000 - val_loss: 0.0259 - val_precision: 1.0000 - val_recall: 0.9917 - learning_rate: 2.0000e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9919 - loss: 0.0361 - precision: 0.9935 - recall: 0.9906\n",
      "Epoch 36: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 6s/step - accuracy: 0.9920 - loss: 0.0362 - precision: 0.9935 - recall: 0.9906 - val_accuracy: 1.0000 - val_loss: 0.0254 - val_precision: 1.0000 - val_recall: 0.9917 - learning_rate: 2.0000e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9971 - loss: 0.0302 - precision: 0.9975 - recall: 0.9971\n",
      "Epoch 37: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 6s/step - accuracy: 0.9971 - loss: 0.0302 - precision: 0.9976 - recall: 0.9971 - val_accuracy: 0.9917 - val_loss: 0.0265 - val_precision: 1.0000 - val_recall: 0.9917 - learning_rate: 2.0000e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 1.0000 - loss: 0.0227 - precision: 1.0000 - recall: 0.9998\n",
      "Epoch 38: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 6s/step - accuracy: 1.0000 - loss: 0.0228 - precision: 1.0000 - recall: 0.9997 - val_accuracy: 0.9917 - val_loss: 0.0271 - val_precision: 1.0000 - val_recall: 0.9917 - learning_rate: 2.0000e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9915 - loss: 0.0424 - precision: 0.9915 - recall: 0.9915\n",
      "Epoch 39: val_accuracy did not improve from 1.00000\n",
      "\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 6s/step - accuracy: 0.9917 - loss: 0.0417 - precision: 0.9917 - recall: 0.9917 - val_accuracy: 0.9917 - val_loss: 0.0258 - val_precision: 1.0000 - val_recall: 0.9917 - learning_rate: 2.0000e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9975 - loss: 0.0330 - precision: 0.9975 - recall: 0.9975\n",
      "Epoch 40: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 6s/step - accuracy: 0.9974 - loss: 0.0333 - precision: 0.9974 - recall: 0.9974 - val_accuracy: 0.9917 - val_loss: 0.0256 - val_precision: 1.0000 - val_recall: 0.9917 - learning_rate: 4.0000e-05\n",
      "Epoch 41/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9925 - loss: 0.0444 - precision: 0.9937 - recall: 0.9925\n",
      "Epoch 41: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 6s/step - accuracy: 0.9927 - loss: 0.0437 - precision: 0.9939 - recall: 0.9927 - val_accuracy: 1.0000 - val_loss: 0.0250 - val_precision: 1.0000 - val_recall: 0.9917 - learning_rate: 4.0000e-05\n",
      "Epoch 42/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9972 - loss: 0.0313 - precision: 0.9972 - recall: 0.9972\n",
      "Epoch 42: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 6s/step - accuracy: 0.9970 - loss: 0.0314 - precision: 0.9970 - recall: 0.9970 - val_accuracy: 1.0000 - val_loss: 0.0246 - val_precision: 1.0000 - val_recall: 0.9917 - learning_rate: 4.0000e-05\n",
      "Epoch 43/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9904 - loss: 0.0439 - precision: 0.9923 - recall: 0.9876\n",
      "Epoch 43: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 6s/step - accuracy: 0.9907 - loss: 0.0435 - precision: 0.9925 - recall: 0.9878 - val_accuracy: 1.0000 - val_loss: 0.0250 - val_precision: 1.0000 - val_recall: 0.9917 - learning_rate: 4.0000e-05\n",
      "Epoch 44/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9930 - loss: 0.0316 - precision: 0.9951 - recall: 0.9921\n",
      "Epoch 44: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 6s/step - accuracy: 0.9930 - loss: 0.0319 - precision: 0.9951 - recall: 0.9920 - val_accuracy: 1.0000 - val_loss: 0.0245 - val_precision: 1.0000 - val_recall: 0.9917 - learning_rate: 4.0000e-05\n",
      "Epoch 45/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9983 - loss: 0.0200 - precision: 0.9991 - recall: 0.9958\n",
      "Epoch 45: val_accuracy did not improve from 1.00000\n",
      "\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 6s/step - accuracy: 0.9981 - loss: 0.0204 - precision: 0.9990 - recall: 0.9957 - val_accuracy: 1.0000 - val_loss: 0.0245 - val_precision: 1.0000 - val_recall: 0.9917 - learning_rate: 4.0000e-05\n",
      "Epoch 46/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9944 - loss: 0.0299 - precision: 0.9944 - recall: 0.9944\n",
      "Epoch 46: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 6s/step - accuracy: 0.9944 - loss: 0.0298 - precision: 0.9944 - recall: 0.9944 - val_accuracy: 1.0000 - val_loss: 0.0244 - val_precision: 1.0000 - val_recall: 0.9917 - learning_rate: 8.0000e-06\n",
      "Epoch 47/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9998 - loss: 0.0407 - precision: 0.9998 - recall: 0.9967\n",
      "Epoch 47: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 6s/step - accuracy: 0.9997 - loss: 0.0406 - precision: 0.9997 - recall: 0.9966 - val_accuracy: 1.0000 - val_loss: 0.0244 - val_precision: 1.0000 - val_recall: 0.9917 - learning_rate: 8.0000e-06\n",
      "Epoch 48/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9935 - loss: 0.0305 - precision: 0.9981 - recall: 0.9919\n",
      "Epoch 48: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 6s/step - accuracy: 0.9935 - loss: 0.0306 - precision: 0.9980 - recall: 0.9919 - val_accuracy: 1.0000 - val_loss: 0.0243 - val_precision: 1.0000 - val_recall: 0.9917 - learning_rate: 8.0000e-06\n",
      "Epoch 49/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9898 - loss: 0.0508 - precision: 0.9917 - recall: 0.9898\n",
      "Epoch 49: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 7s/step - accuracy: 0.9901 - loss: 0.0501 - precision: 0.9919 - recall: 0.9901 - val_accuracy: 1.0000 - val_loss: 0.0243 - val_precision: 1.0000 - val_recall: 0.9917 - learning_rate: 8.0000e-06\n",
      "Epoch 50/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9939 - loss: 0.0272 - precision: 0.9942 - recall: 0.9939\n",
      "Epoch 50: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 6s/step - accuracy: 0.9938 - loss: 0.0273 - precision: 0.9942 - recall: 0.9938 - val_accuracy: 1.0000 - val_loss: 0.0243 - val_precision: 1.0000 - val_recall: 0.9917 - learning_rate: 8.0000e-06\n",
      "Restoring model weights from the end of the best epoch: 50.\n",
      "Epoch 1/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9895 - loss: 0.0336 - precision_1: 0.9895 - recall_1: 0.9895\n",
      "Epoch 1: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 7s/step - accuracy: 0.9898 - loss: 0.0333 - precision_1: 0.9898 - recall_1: 0.9898 - val_accuracy: 1.0000 - val_loss: 0.0243 - val_precision_1: 1.0000 - val_recall_1: 1.0000 - learning_rate: 1.0000e-04\n",
      "Epoch 2/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9974 - loss: 0.0341 - precision_1: 0.9981 - recall_1: 0.9974\n",
      "Epoch 2: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 6s/step - accuracy: 0.9971 - loss: 0.0343 - precision_1: 0.9979 - recall_1: 0.9971 - val_accuracy: 0.9917 - val_loss: 0.0247 - val_precision_1: 1.0000 - val_recall_1: 0.9917 - learning_rate: 1.0000e-04\n",
      "Epoch 3/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9872 - loss: 0.0389 - precision_1: 0.9872 - recall_1: 0.9872\n",
      "Epoch 3: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 7s/step - accuracy: 0.9870 - loss: 0.0391 - precision_1: 0.9870 - recall_1: 0.9870 - val_accuracy: 0.9917 - val_loss: 0.0234 - val_precision_1: 1.0000 - val_recall_1: 0.9917 - learning_rate: 1.0000e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9923 - loss: 0.0431 - precision_1: 0.9922 - recall_1: 0.9869\n",
      "Epoch 4: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 6s/step - accuracy: 0.9925 - loss: 0.0426 - precision_1: 0.9924 - recall_1: 0.9871 - val_accuracy: 1.0000 - val_loss: 0.0230 - val_precision_1: 1.0000 - val_recall_1: 1.0000 - learning_rate: 1.0000e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9903 - loss: 0.0394 - precision_1: 0.9962 - recall_1: 0.9903\n",
      "Epoch 5: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 6s/step - accuracy: 0.9904 - loss: 0.0391 - precision_1: 0.9963 - recall_1: 0.9904 - val_accuracy: 1.0000 - val_loss: 0.0227 - val_precision_1: 1.0000 - val_recall_1: 0.9917 - learning_rate: 1.0000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9940 - loss: 0.0339 - precision_1: 0.9940 - recall_1: 0.9901\n",
      "Epoch 6: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 6s/step - accuracy: 0.9941 - loss: 0.0338 - precision_1: 0.9940 - recall_1: 0.9901 - val_accuracy: 0.9917 - val_loss: 0.0231 - val_precision_1: 1.0000 - val_recall_1: 0.9917 - learning_rate: 1.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 1.0000 - loss: 0.0306 - precision_1: 1.0000 - recall_1: 0.9976\n",
      "Epoch 7: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 6s/step - accuracy: 1.0000 - loss: 0.0304 - precision_1: 1.0000 - recall_1: 0.9976 - val_accuracy: 1.0000 - val_loss: 0.0220 - val_precision_1: 1.0000 - val_recall_1: 1.0000 - learning_rate: 1.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9944 - loss: 0.0373 - precision_1: 0.9944 - recall_1: 0.9944\n",
      "Epoch 8: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 6s/step - accuracy: 0.9945 - loss: 0.0370 - precision_1: 0.9945 - recall_1: 0.9945 - val_accuracy: 1.0000 - val_loss: 0.0215 - val_precision_1: 1.0000 - val_recall_1: 1.0000 - learning_rate: 1.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9876 - loss: 0.0405 - precision_1: 0.9876 - recall_1: 0.9815\n",
      "Epoch 9: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 6s/step - accuracy: 0.9877 - loss: 0.0402 - precision_1: 0.9877 - recall_1: 0.9818 - val_accuracy: 0.9917 - val_loss: 0.0231 - val_precision_1: 1.0000 - val_recall_1: 0.9917 - learning_rate: 1.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9904 - loss: 0.0461 - precision_1: 0.9924 - recall_1: 0.9860\n",
      "Epoch 10: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 6s/step - accuracy: 0.9905 - loss: 0.0456 - precision_1: 0.9926 - recall_1: 0.9863 - val_accuracy: 1.0000 - val_loss: 0.0215 - val_precision_1: 1.0000 - val_recall_1: 0.9917 - learning_rate: 1.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9975 - loss: 0.0316 - precision_1: 0.9985 - recall_1: 0.9845\n",
      "Epoch 11: val_accuracy did not improve from 1.00000\n",
      "\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 6s/step - accuracy: 0.9974 - loss: 0.0316 - precision_1: 0.9984 - recall_1: 0.9848 - val_accuracy: 1.0000 - val_loss: 0.0219 - val_precision_1: 1.0000 - val_recall_1: 0.9917 - learning_rate: 1.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9870 - loss: 0.0415 - precision_1: 0.9869 - recall_1: 0.9836\n",
      "Epoch 12: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 6s/step - accuracy: 0.9873 - loss: 0.0411 - precision_1: 0.9872 - recall_1: 0.9838 - val_accuracy: 1.0000 - val_loss: 0.0217 - val_precision_1: 1.0000 - val_recall_1: 0.9917 - learning_rate: 2.0000e-05\n",
      "Epoch 13/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9944 - loss: 0.0375 - precision_1: 0.9956 - recall_1: 0.9867\n",
      "Epoch 13: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 6s/step - accuracy: 0.9945 - loss: 0.0371 - precision_1: 0.9957 - recall_1: 0.9869 - val_accuracy: 1.0000 - val_loss: 0.0212 - val_precision_1: 1.0000 - val_recall_1: 0.9917 - learning_rate: 2.0000e-05\n",
      "Epoch 14/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9934 - loss: 0.0321 - precision_1: 0.9934 - recall_1: 0.9927\n",
      "Epoch 14: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 6s/step - accuracy: 0.9934 - loss: 0.0325 - precision_1: 0.9934 - recall_1: 0.9926 - val_accuracy: 1.0000 - val_loss: 0.0211 - val_precision_1: 1.0000 - val_recall_1: 0.9917 - learning_rate: 2.0000e-05\n",
      "Epoch 15/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9904 - loss: 0.0389 - precision_1: 0.9938 - recall_1: 0.9836\n",
      "Epoch 15: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 6s/step - accuracy: 0.9906 - loss: 0.0384 - precision_1: 0.9939 - recall_1: 0.9839 - val_accuracy: 1.0000 - val_loss: 0.0211 - val_precision_1: 1.0000 - val_recall_1: 0.9917 - learning_rate: 2.0000e-05\n",
      "Epoch 16/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9985 - loss: 0.0274 - precision_1: 0.9985 - recall_1: 0.9932\n",
      "Epoch 16: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 6s/step - accuracy: 0.9983 - loss: 0.0276 - precision_1: 0.9983 - recall_1: 0.9931 - val_accuracy: 1.0000 - val_loss: 0.0212 - val_precision_1: 1.0000 - val_recall_1: 0.9917 - learning_rate: 2.0000e-05\n",
      "Epoch 17/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9969 - loss: 0.0304 - precision_1: 0.9969 - recall_1: 0.9900\n",
      "Epoch 17: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 6s/step - accuracy: 0.9970 - loss: 0.0302 - precision_1: 0.9969 - recall_1: 0.9903 - val_accuracy: 1.0000 - val_loss: 0.0210 - val_precision_1: 1.0000 - val_recall_1: 0.9917 - learning_rate: 2.0000e-05\n",
      "Epoch 18/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9986 - loss: 0.0213 - precision_1: 0.9985 - recall_1: 0.9972\n",
      "Epoch 18: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 6s/step - accuracy: 0.9984 - loss: 0.0216 - precision_1: 0.9984 - recall_1: 0.9970 - val_accuracy: 1.0000 - val_loss: 0.0210 - val_precision_1: 1.0000 - val_recall_1: 0.9917 - learning_rate: 2.0000e-05\n",
      "Epoch 19/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9956 - loss: 0.0299 - precision_1: 0.9956 - recall_1: 0.9956\n",
      "Epoch 19: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 6s/step - accuracy: 0.9957 - loss: 0.0296 - precision_1: 0.9957 - recall_1: 0.9957 - val_accuracy: 1.0000 - val_loss: 0.0208 - val_precision_1: 1.0000 - val_recall_1: 0.9917 - learning_rate: 2.0000e-05\n",
      "Epoch 20/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9972 - loss: 0.0316 - precision_1: 0.9977 - recall_1: 0.9935\n",
      "Epoch 20: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 7s/step - accuracy: 0.9970 - loss: 0.0319 - precision_1: 0.9976 - recall_1: 0.9931 - val_accuracy: 1.0000 - val_loss: 0.0209 - val_precision_1: 1.0000 - val_recall_1: 0.9917 - learning_rate: 2.0000e-05\n",
      "Epoch 21/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9950 - loss: 0.0290 - precision_1: 0.9950 - recall_1: 0.9934\n",
      "Epoch 21: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 7s/step - accuracy: 0.9950 - loss: 0.0290 - precision_1: 0.9950 - recall_1: 0.9934 - val_accuracy: 1.0000 - val_loss: 0.0209 - val_precision_1: 1.0000 - val_recall_1: 0.9917 - learning_rate: 2.0000e-05\n",
      "Epoch 22/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9976 - loss: 0.0253 - precision_1: 0.9992 - recall_1: 0.9976\n",
      "Epoch 22: val_accuracy did not improve from 1.00000\n",
      "\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 6s/step - accuracy: 0.9974 - loss: 0.0254 - precision_1: 0.9991 - recall_1: 0.9974 - val_accuracy: 1.0000 - val_loss: 0.0208 - val_precision_1: 1.0000 - val_recall_1: 0.9917 - learning_rate: 2.0000e-05\n",
      "Epoch 23/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9926 - loss: 0.0316 - precision_1: 0.9925 - recall_1: 0.9880\n",
      "Epoch 23: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 6s/step - accuracy: 0.9927 - loss: 0.0315 - precision_1: 0.9926 - recall_1: 0.9883 - val_accuracy: 1.0000 - val_loss: 0.0208 - val_precision_1: 1.0000 - val_recall_1: 0.9917 - learning_rate: 4.0000e-06\n",
      "Epoch 24/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9859 - loss: 0.0414 - precision_1: 0.9912 - recall_1: 0.9859\n",
      "Epoch 24: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 7s/step - accuracy: 0.9862 - loss: 0.0409 - precision_1: 0.9915 - recall_1: 0.9862 - val_accuracy: 1.0000 - val_loss: 0.0208 - val_precision_1: 1.0000 - val_recall_1: 0.9917 - learning_rate: 4.0000e-06\n",
      "Epoch 25/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9988 - loss: 0.0157 - precision_1: 1.0000 - recall_1: 0.9988\n",
      "Epoch 25: val_accuracy did not improve from 1.00000\n",
      "\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 6s/step - accuracy: 0.9988 - loss: 0.0158 - precision_1: 1.0000 - recall_1: 0.9988 - val_accuracy: 1.0000 - val_loss: 0.0208 - val_precision_1: 1.0000 - val_recall_1: 0.9917 - learning_rate: 4.0000e-06\n",
      "Epoch 26/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9897 - loss: 0.0343 - precision_1: 0.9919 - recall_1: 0.9834\n",
      "Epoch 26: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 6s/step - accuracy: 0.9898 - loss: 0.0343 - precision_1: 0.9920 - recall_1: 0.9836 - val_accuracy: 1.0000 - val_loss: 0.0208 - val_precision_1: 1.0000 - val_recall_1: 0.9917 - learning_rate: 1.0000e-06\n",
      "Epoch 27/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9958 - loss: 0.0263 - precision_1: 0.9984 - recall_1: 0.9915\n",
      "Epoch 27: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 6s/step - accuracy: 0.9957 - loss: 0.0265 - precision_1: 0.9984 - recall_1: 0.9914 - val_accuracy: 1.0000 - val_loss: 0.0208 - val_precision_1: 1.0000 - val_recall_1: 0.9917 - learning_rate: 1.0000e-06\n",
      "Epoch 28/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 1.0000 - loss: 0.0147 - precision_1: 1.0000 - recall_1: 0.9999\n",
      "Epoch 28: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 6s/step - accuracy: 1.0000 - loss: 0.0151 - precision_1: 1.0000 - recall_1: 0.9998 - val_accuracy: 1.0000 - val_loss: 0.0208 - val_precision_1: 1.0000 - val_recall_1: 0.9917 - learning_rate: 1.0000e-06\n",
      "Epoch 29/50\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9955 - loss: 0.0198 - precision_1: 0.9982 - recall_1: 0.9955\n",
      "Epoch 29: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 7s/step - accuracy: 0.9955 - loss: 0.0200 - precision_1: 0.9981 - recall_1: 0.9955 - val_accuracy: 1.0000 - val_loss: 0.0208 - val_precision_1: 1.0000 - val_recall_1: 0.9917 - learning_rate: 1.0000e-06\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Functional' object has no attribute '_get_save_spec'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 123\u001b[39m\n\u001b[32m    120\u001b[39m model.save(\u001b[33m\"\u001b[39m\u001b[33mvgg_face_final.h5\u001b[39m\u001b[33m\"\u001b[39m)  \u001b[38;5;66;03m# định dạng thư mục\u001b[39;00m\n\u001b[32m    122\u001b[39m \u001b[38;5;66;03m# Chuyển đổi và lưu mô hình sang ONNX\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m123\u001b[39m model_proto, _ = \u001b[43mtf2onnx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_keras\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvgg_face_final.onnx\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    124\u001b[39m onnx.save(model_proto, \u001b[33m\"\u001b[39m\u001b[33mvgg_face_final.onnx\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    126\u001b[39m \u001b[38;5;66;03m# Đánh giá trên tập kiểm tra\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\Study\\Projects\\HK6\\XLA\\.venv\\Lib\\site-packages\\tf2onnx\\convert.py:446\u001b[39m, in \u001b[36mfrom_keras\u001b[39m\u001b[34m(model, input_signature, opset, custom_ops, custom_op_handlers, custom_rewriter, inputs_as_nchw, outputs_as_nchw, extra_opset, shape_override, target, large_model, output_path, optimizers)\u001b[39m\n\u001b[32m    443\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msaving\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m saving_utils \u001b[38;5;28;01mas\u001b[39;00m _saving_utils \u001b[38;5;66;03m# pylint: disable=import-outside-toplevel\u001b[39;00m\n\u001b[32m    445\u001b[39m \u001b[38;5;66;03m# let tensorflow do the checking if model is a valid model\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m446\u001b[39m function = \u001b[43m_saving_utils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrace_model_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_signature\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    447\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    448\u001b[39m     concrete_func = function.get_concrete_function()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\Study\\Projects\\HK6\\XLA\\.venv\\Lib\\site-packages\\tensorflow\\python\\keras\\saving\\saving_utils.py:115\u001b[39m, in \u001b[36mtrace_model_call\u001b[39m\u001b[34m(model, input_signature)\u001b[39m\n\u001b[32m    112\u001b[39m     input_signature = model.call.input_signature\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m input_signature \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m   input_signature = \u001b[43mmodel_input_signature\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    117\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m input_signature \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    118\u001b[39m   raise_model_input_error(model)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\Study\\Projects\\HK6\\XLA\\.venv\\Lib\\site-packages\\tensorflow\\python\\keras\\saving\\saving_utils.py:74\u001b[39m, in \u001b[36mmodel_input_signature\u001b[39m\u001b[34m(model, keep_original_batch_size)\u001b[39m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmodel_input_signature\u001b[39m(model, keep_original_batch_size=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m     54\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Inspect model to get its input signature.\u001b[39;00m\n\u001b[32m     55\u001b[39m \n\u001b[32m     56\u001b[39m \u001b[33;03m  The model's input signature is a list with a single (possibly-nested) object.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     72\u001b[39m \u001b[33;03m    TensorSpecs. This list does not contain the `training` argument.\u001b[39;00m\n\u001b[32m     73\u001b[39m \u001b[33;03m  \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m   input_specs = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_save_spec\u001b[49m(dynamic_batch=\u001b[38;5;129;01mnot\u001b[39;00m keep_original_batch_size)  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[32m     75\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m input_specs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     76\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mAttributeError\u001b[39m: 'Functional' object has no attribute '_get_save_spec'"
     ]
    }
   ],
   "source": [
    "# Cấu hình siêu tham số\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 50\n",
    "LEARNING_RATE = 0.001\n",
    "FINE_TUNE_LAYERS = 4  # Số tầng cuối của VGG16 để tinh chỉnh\n",
    "DATA_DIR = \"dataset\"\n",
    "TRAIN_DIR = os.path.join(DATA_DIR, \"train\")\n",
    "VAL_DIR = os.path.join(DATA_DIR, \"val\")\n",
    "TEST_DIR = os.path.join(DATA_DIR, \"test\")\n",
    "\n",
    "\n",
    "# Kiểm tra thư mục dữ liệu\n",
    "for directory in [TRAIN_DIR, VAL_DIR, TEST_DIR]:\n",
    "    if not os.path.exists(directory):\n",
    "        raise FileNotFoundError(f\"Thư mục không tồn tại: {directory}\")\n",
    "    \n",
    "# Tạo mô hình VGG16\n",
    "def build_model(num_classes=4):\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    predictions = Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    \n",
    "    # Đóng băng tất cả tầng của VGG16 ban đầu\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Chuẩn bị dữ liệu\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.2,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    brightness_range=[0.8, 1.2],\n",
    "    channel_shift_range=20.0  # Thêm thay đổi màu sắc ngẫu nhiên\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    VAL_DIR,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    TEST_DIR,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "\n",
    "# Tạo và biên dịch mô hình\n",
    "model = build_model(num_classes=4)\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]\n",
    ")\n",
    "\n",
    "# Callbacks\n",
    "log_dir = f\"logs/fit/{datetime.now().strftime('%Y%m%d-%H%M%S')}\"\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=1),\n",
    "    ModelCheckpoint('best_vgg_face.h5', monitor='val_accuracy', save_best_only=True, mode='max', verbose=1),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6, verbose=1),\n",
    "    TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "]\n",
    "\n",
    "# Huấn luyện giai đoạn 1: Chỉ huấn luyện các tầng đầu\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Giai đoạn 2: Tinh chỉnh các tầng cuối của VGG16\n",
    "for layer in model.layers[-FINE_TUNE_LAYERS:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Biên dịch lại với tốc độ học nhỏ hơn\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE / 10),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]\n",
    ")\n",
    "\n",
    "# Tiếp tục huấn luyện\n",
    "history_fine = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "\n",
    "# Save final model (sau khi kết thúc training)\n",
    "model.save(\"vgg_face_final.keras\")  # định dạng thư mục\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fcc1ff7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "ERROR:tf2onnx.tfonnx:rewriter <function rewrite_constant_fold at 0x000001E9BA748040>: exception `np.cast` was removed in the NumPy 2.0 release. Use `np.asarray(arr, dtype=dtype)` instead.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tf2onnx\n",
    "\n",
    "# Tải mô hình từ .h5 hoặc .keras\n",
    "model = tf.keras.models.load_model(\"vgg_face_final.h5\")  # hoặc \"model.keras\"\n",
    "\n",
    "# Chuyển mô hình Keras thành ONNX\n",
    "spec = (tf.TensorSpec((None, *model.input.shape[1:]), tf.float32, name=\"input\"),)\n",
    "onnx_model = tf2onnx.convert.from_keras(model, input_signature=spec)[0]\n",
    "\n",
    "# Lưu ONNX model\n",
    "with open(\"model.onnx\", \"wb\") as f:\n",
    "    f.write(onnx_model.SerializeToString())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc925e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Study\\Projects\\HK6\\XLA\\.venv\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 10 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Functional' object has no attribute '_get_save_spec'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[48]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_model\n\u001b[32m      7\u001b[39m model = load_model(\u001b[33m'\u001b[39m\u001b[33mvgg_face_final.keras\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m onnx_model, _ = \u001b[43mtf2onnx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_keras\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m onnx.save(onnx_model, \u001b[33m'\u001b[39m\u001b[33mnew_model.onnx\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\Study\\Projects\\HK6\\XLA\\.venv\\Lib\\site-packages\\tf2onnx\\convert.py:446\u001b[39m, in \u001b[36mfrom_keras\u001b[39m\u001b[34m(model, input_signature, opset, custom_ops, custom_op_handlers, custom_rewriter, inputs_as_nchw, outputs_as_nchw, extra_opset, shape_override, target, large_model, output_path, optimizers)\u001b[39m\n\u001b[32m    443\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msaving\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m saving_utils \u001b[38;5;28;01mas\u001b[39;00m _saving_utils \u001b[38;5;66;03m# pylint: disable=import-outside-toplevel\u001b[39;00m\n\u001b[32m    445\u001b[39m \u001b[38;5;66;03m# let tensorflow do the checking if model is a valid model\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m446\u001b[39m function = \u001b[43m_saving_utils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrace_model_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_signature\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    447\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    448\u001b[39m     concrete_func = function.get_concrete_function()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\Study\\Projects\\HK6\\XLA\\.venv\\Lib\\site-packages\\tensorflow\\python\\keras\\saving\\saving_utils.py:115\u001b[39m, in \u001b[36mtrace_model_call\u001b[39m\u001b[34m(model, input_signature)\u001b[39m\n\u001b[32m    112\u001b[39m     input_signature = model.call.input_signature\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m input_signature \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m   input_signature = \u001b[43mmodel_input_signature\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    117\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m input_signature \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    118\u001b[39m   raise_model_input_error(model)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\Study\\Projects\\HK6\\XLA\\.venv\\Lib\\site-packages\\tensorflow\\python\\keras\\saving\\saving_utils.py:74\u001b[39m, in \u001b[36mmodel_input_signature\u001b[39m\u001b[34m(model, keep_original_batch_size)\u001b[39m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmodel_input_signature\u001b[39m(model, keep_original_batch_size=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m     54\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Inspect model to get its input signature.\u001b[39;00m\n\u001b[32m     55\u001b[39m \n\u001b[32m     56\u001b[39m \u001b[33;03m  The model's input signature is a list with a single (possibly-nested) object.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     72\u001b[39m \u001b[33;03m    TensorSpecs. This list does not contain the `training` argument.\u001b[39;00m\n\u001b[32m     73\u001b[39m \u001b[33;03m  \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m   input_specs = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_save_spec\u001b[49m(dynamic_batch=\u001b[38;5;129;01mnot\u001b[39;00m keep_original_batch_size)  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[32m     75\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m input_specs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     76\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mAttributeError\u001b[39m: 'Functional' object has no attribute '_get_save_spec'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tf2onnx\n",
    "import onnx\n",
    "from tensorflow import keras\n",
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('vgg_face_final.keras')\n",
    "\n",
    "onnx_model, _ = tf2onnx.convert.from_keras(model)\n",
    "onnx.save(onnx_model, 'new_model.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e0da024d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys in history: dict_keys(['accuracy', 'loss', 'precision', 'recall', 'val_accuracy', 'val_loss', 'val_precision', 'val_recall', 'learning_rate'])\n",
      "Keys in history_fine: dict_keys(['accuracy', 'loss', 'precision_1', 'recall_1', 'val_accuracy', 'val_loss', 'val_precision_1', 'val_recall_1', 'learning_rate'])\n"
     ]
    }
   ],
   "source": [
    "print(\"Keys in history:\", history.history.keys())\n",
    "print(\"Keys in history_fine:\", history_fine.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16640b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DangDuong': 0, 'HuuTho': 1, 'ManhTuong': 2, 'QuanPhan': 3}\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "print(test_generator.class_indices)  # Xem danh sách lớp\n",
    "print(len(test_generator.class_indices))  # Kiểm tra số lớp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "82bb204e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys in history: dict_keys(['accuracy', 'loss', 'precision', 'recall', 'val_accuracy', 'val_loss', 'val_precision', 'val_recall', 'learning_rate'])\n",
      "Keys in history_fine: dict_keys(['accuracy', 'loss', 'precision_1', 'recall_1', 'val_accuracy', 'val_loss', 'val_precision_1', 'val_recall_1', 'learning_rate'])\n"
     ]
    }
   ],
   "source": [
    "# Kiểm tra các khóa\n",
    "print(\"Keys in history:\", history.history.keys())\n",
    "print(\"Keys in history_fine:\", history_fine.history.keys())\n",
    "\n",
    "# Định nghĩa ánh xạ\n",
    "metric_pairs = {\n",
    "    'accuracy': ('accuracy', 'accuracy'),\n",
    "    'precision': ('precision', 'precision_1'),\n",
    "    'recall': ('recall', 'recall_1'),\n",
    "    'val_accuracy': ('val_accuracy', 'val_accuracy'),\n",
    "    'val_precision': ('val_precision', 'val_precision_1'),\n",
    "    'val_recall': ('val_recall', 'val_recall_1')\n",
    "}\n",
    "\n",
    "# Kết hợp history\n",
    "full_history = {\n",
    "    metric: history.history[history_key] + history_fine.history[fine_key]\n",
    "    for metric, (history_key, fine_key) in metric_pairs.items()\n",
    "}\n",
    "\n",
    "# Tiếp tục vẽ biểu đồ hoặc xử lý dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdad2578",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.python.distribute.distribution_strategy_context'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_model\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# Đánh giá trên tập kiểm tra\u001b[39;00m\n\u001b[32m      3\u001b[39m model = load_model(\u001b[33m'\u001b[39m\u001b[33mvgg_face_final.keras\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\Study\\Projects\\HK6\\XLA\\.venv\\Lib\\site-packages\\keras\\__init__.py:21\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[33;03m\"\"\"Implementation of the Keras API, the high-level API of TensorFlow.\u001b[39;00m\n\u001b[32m     16\u001b[39m \n\u001b[32m     17\u001b[39m \u001b[33;03mDetailed documentation and user guides are available at\u001b[39;00m\n\u001b[32m     18\u001b[39m \u001b[33;03m[keras.io](https://keras.io).\u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m models\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mengine\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01minput_layer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Input\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mengine\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msequential\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Sequential\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\Study\\Projects\\HK6\\XLA\\.venv\\Lib\\site-packages\\keras\\models\\__init__.py:18\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Copyright 2022 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[33;03m\"\"\"Keras models API.\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mengine\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfunctional\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Functional\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mengine\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msequential\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mengine\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtraining\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Model\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\Study\\Projects\\HK6\\XLA\\.venv\\Lib\\site-packages\\keras\\engine\\functional.py:24\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mitertools\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mwarnings\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcompat\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtf\u001b[39;00m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m backend\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdtensor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m layout_map \u001b[38;5;28;01mas\u001b[39;00m layout_map_lib\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\Study\\Projects\\HK6\\XLA\\.venv\\Lib\\site-packages\\tensorflow\\__init__.py:45\u001b[39m\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf2 \u001b[38;5;28;01mas\u001b[39;00m _tf2\n\u001b[32m     43\u001b[39m _tf2.enable()\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_api\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __internal__\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_api\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __operators__\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_api\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m audio\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\Study\\Projects\\HK6\\XLA\\.venv\\Lib\\site-packages\\tensorflow\\_api\\v2\\__internal__\\__init__.py:11\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m decorator\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dispatch\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m eager_context\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m feature_column\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\Study\\Projects\\HK6\\XLA\\.venv\\Lib\\site-packages\\tensorflow\\_api\\v2\\__internal__\\distribute\\__init__.py:11\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m interim\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m multi_process_runner\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistribute\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistribution_strategy_context\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m variable_sync_on_read_context\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistribute\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmerge_call_interim\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m strategy_supports_no_merge_call\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistribute\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msharded_variable\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ShardedVariable\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'tensorflow.python.distribute.distribution_strategy_context'"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "# Đánh giá trên tập kiểm tra\n",
    "model = load_model('vgg_face_final.keras')\n",
    "\n",
    "test_loss, test_acc, test_precision, test_recall = model.evaluate(test_generator)\n",
    "print(f\"\\nKết quả trên tập kiểm tra:\")\n",
    "print(f\"Độ mất mát: {test_loss:.4f}\")\n",
    "print(f\"Độ chính xác: {test_acc:.4f}\")\n",
    "print(f\"Độ chính xác từng lớp: {test_precision:.4f}\")\n",
    "print(f\"Độ phủ: {test_recall:.4f}\")\n",
    "\n",
    "# Vẽ và lưu biểu đồ\n",
    "# Kết hợp lịch sử huấn luyện từ cả hai giai đoạn\n",
    "metrics = ['accuracy', 'loss', 'precision', 'recall']\n",
    "full_history = {}\n",
    "for metric in metrics:\n",
    "    full_history[metric] = history.history[metric] + history_fine.history[metric]\n",
    "    full_history[f'val_{metric}'] = history.history[f'val_{metric}'] + history_fine.history[f'val_{metric}']\n",
    "\n",
    "# Vẽ biểu đồ độ chính xác\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(full_history['accuracy'], label='Độ chính xác huấn luyện')\n",
    "plt.plot(full_history['val_accuracy'], label='Độ chính xác xác thực')\n",
    "plt.title('Learning Curve - Độ chính xác')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Độ chính xác')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.close()\n",
    "\n",
    "# Vẽ biểu đồ mất mát\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(full_history['loss'], label='Mất mát huấn luyện')\n",
    "plt.plot(full_history['val_loss'], label='Mất mát xác thực')\n",
    "plt.title('Learning Curve - Mất mát')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Mất mát')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.close()\n",
    "\n",
    "# Vẽ biểu đồ precision\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(full_history['precision'], label='Precision huấn luyện')\n",
    "plt.plot(full_history['val_precision'], label='Precision xác thực')\n",
    "plt.title('Precision Curve')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.close()\n",
    "\n",
    "# Vẽ biểu đồ recall\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(full_history['recall'], label='Recall huấn luyện')\n",
    "plt.plot(full_history['val_recall'], label='Recall xác thực')\n",
    "plt.title('Recall Curve')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Recall')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513b6246",
   "metadata": {},
   "source": [
    "## Chuyển model .h5 sang onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8134eecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float32\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[43]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      8\u001b[39m model = load_model(\u001b[33m'\u001b[39m\u001b[33mvgg_face_final.h5\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(model.dtype)\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[43mtf2onnx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtf_loader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m onnx_model, _ = tf2onnx.convert.from_keras(model)\n\u001b[32m     13\u001b[39m onnx.save(onnx_model, \u001b[33m'\u001b[39m\u001b[33mnew_model.onnx\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tf2onnx\n",
    "import onnx\n",
    "from tensorflow import keras\n",
    "from keras.models import load_model\n",
    "import tf2onnx.tf_loader\n",
    "\n",
    "model = load_model('vgg_face_final.h5')\n",
    "\n",
    "print(model.dtype)\n",
    "tf2onnx.tf_loader(model)\n",
    "onnx_model, _ = tf2onnx.convert.from_keras(model)\n",
    "onnx.save(onnx_model, 'new_model.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcba88a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys in history: dict_keys(['accuracy', 'loss', 'precision', 'recall', 'val_accuracy', 'val_loss', 'val_precision', 'val_recall', 'learning_rate'])\n",
      "Keys in history_fine: dict_keys(['accuracy', 'loss', 'precision_1', 'recall_1', 'val_accuracy', 'val_loss', 'val_precision_1', 'val_recall_1', 'learning_rate'])\n"
     ]
    }
   ],
   "source": [
    "print(\"Keys in history:\", history.history.keys())\n",
    "print(\"Keys in history_fine:\", history_fine.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6647461b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=tf\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:tensorflow:From f:\\Study\\Projects\\HK6\\XLA\\.venv\\Lib\\site-packages\\tf2onnx\\tf_loader.py:68: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From f:\\Study\\Projects\\HK6\\XLA\\.venv\\Lib\\site-packages\\tf2onnx\\tf_loader.py:72: The name tf.train.import_meta_graph is deprecated. Please use tf.compat.v1.train.import_meta_graph instead.\n",
      "\n",
      "<frozen runpy>:128: RuntimeWarning: 'tf2onnx.convert' found in sys.modules after import of package 'tf2onnx', but prior to execution of 'tf2onnx.convert'; this may result in unpredictable behaviour\n",
      "2025-05-08 22:43:29,995 - WARNING - ***IMPORTANT*** Installed protobuf is not cpp accelerated. Conversion will be extremely slow. See https://github.com/onnx/tensorflow-onnx/issues/1557\n",
      "2025-05-08 22:43:29,995 - WARNING - '--tag' not specified for saved_model. Using --tag serve\n",
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"f:\\Study\\Projects\\HK6\\XLA\\.venv\\Lib\\site-packages\\tf2onnx\\convert.py\", line 714, in <module>\n",
      "    main()\n",
      "  File \"f:\\Study\\Projects\\HK6\\XLA\\.venv\\Lib\\site-packages\\tf2onnx\\convert.py\", line 242, in main\n",
      "    graph_def, inputs, outputs, initialized_tables, tensors_to_rename = tf_loader.from_saved_model(\n",
      "                                                                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"f:\\Study\\Projects\\HK6\\XLA\\.venv\\Lib\\site-packages\\tf2onnx\\tf_loader.py\", line 636, in from_saved_model\n",
      "    _from_saved_model_v2(model_path, input_names, output_names,\n",
      "  File \"f:\\Study\\Projects\\HK6\\XLA\\.venv\\Lib\\site-packages\\tf2onnx\\tf_loader.py\", line 570, in _from_saved_model_v2\n",
      "    imported = tf.saved_model.load(model_path, tags=tag)  # pylint: disable=no-value-for-parameter\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"f:\\Study\\Projects\\HK6\\XLA\\.venv\\Lib\\site-packages\\tensorflow\\python\\saved_model\\load.py\", line 912, in load\n",
      "    result = load_partial(export_dir, None, tags, options)[\"root\"]\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"f:\\Study\\Projects\\HK6\\XLA\\.venv\\Lib\\site-packages\\tensorflow\\python\\saved_model\\load.py\", line 1016, in load_partial\n",
      "    loader_impl.parse_saved_model_with_debug_info(export_dir))\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"f:\\Study\\Projects\\HK6\\XLA\\.venv\\Lib\\site-packages\\tensorflow\\python\\saved_model\\loader_impl.py\", line 59, in parse_saved_model_with_debug_info\n",
      "    saved_model = parse_saved_model(export_dir)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"f:\\Study\\Projects\\HK6\\XLA\\.venv\\Lib\\site-packages\\tensorflow\\python\\saved_model\\loader_impl.py\", line 119, in parse_saved_model\n",
      "    raise IOError(\n",
      "OSError: SavedModel file does not exist at: vgg_face_saved_model.h5\\{saved_model.pbtxt|saved_model.pb}\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tf2onnx\n",
    "\n",
    "# Tải mô hình\n",
    "model = tf.keras.models.load_model(\"vgg_face_final.h5\")\n",
    "\n",
    "# Lưu lại dưới dạng SavedModel\n",
    "model.save(\"vgg_face_saved_model.h5\", save_format=\"tf\")\n",
    "\n",
    "# Chuyển đổi sang ONNX\n",
    "onnx_model_path = \"vgg_face_final.onnx\"\n",
    "!python -m tf2onnx.convert \\\n",
    "    --saved-model vgg_face_saved_model.h5 \\\n",
    "    --output {onnx_model_path} \\\n",
    "    --opset 13"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f95331a",
   "metadata": {},
   "source": [
    "## Tải face_detector từ DNN-based Face Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59174a1",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'cv2.dnn' has no attribute 'writeToONNX'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     15\u001b[39m net.setInput(dummy_input)\n\u001b[32m     16\u001b[39m output = net.forward()\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m onnx_model = \u001b[43mcv2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwriteToONNX\u001b[49m(net, dummy_input.shape)\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# Lưu mô hình ONNX\u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(output_onnx_path, \u001b[33m'\u001b[39m\u001b[33mwb\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[31mAttributeError\u001b[39m: module 'cv2.dnn' has no attribute 'writeToONNX'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import onnx\n",
    "import numpy as np\n",
    "\n",
    "# Đường dẫn đến tệp Caffe\n",
    "proto_path = r\"F:\\Study\\Projects\\HK6\\XLA\\Project\\FaceDetection\\deploy.prototxt\"\n",
    "model_path = r\"F:\\Study\\Projects\\HK6\\XLA\\Project\\FaceDetection\\res10_300x300_ssd_iter_140000_fp16.caffemodel\"\n",
    "output_onnx_path = r\"F:\\Study\\Projects\\HK6\\XLA\\Project\\FaceDetection\\face_detector.onnx\"\n",
    "\n",
    "# Tải mô hình Caffe\n",
    "net = cv2.dnn.readNetFromCaffe(proto_path, model_path)\n",
    "\n",
    "# Chuyển đổi sang ONNX\n",
    "dummy_input = cv2.dnn.blobFromImage(np.zeros((300, 300, 3)), 1.0, (300, 300), (104.0, 177.0, 123.0))\n",
    "net.setInput(dummy_input)\n",
    "output = net.forward()\n",
    "onnx_model = cv2.dnn.writeToONNX(net, dummy_input.shape)\n",
    "\n",
    "\n",
    "# Lưu mô hình ONNX\n",
    "with open(output_onnx_path, 'wb') as f:\n",
    "    f.write(onnx_model.SerializeToString())\n",
    "\n",
    "print(f\"Model saved to {output_onnx_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda9805d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected face: (240, 260, 429, 449)\n",
      "Detected: Quân Phan, Box: (240, 260, 429, 449)\n",
      "Detected face: (242, 258, 430, 446)\n",
      "Detected: Quân Phan, Box: (242, 258, 430, 446)\n",
      "Detected face: (241, 258, 432, 449)\n",
      "Detected: Quân Phan, Box: (241, 258, 432, 449)\n",
      "Detected face: (242, 258, 430, 446)\n",
      "Detected: Quân Phan, Box: (242, 258, 430, 446)\n",
      "Detected face: (240, 259, 427, 446)\n",
      "Detected: Quân Phan, Box: (240, 259, 427, 446)\n",
      "Detected face: (314, 255, 515, 456)\n",
      "Detected: Trịnh Hửu Thọ, Box: (314, 255, 515, 456)\n",
      "Detected face: (84, 128, 223, 267)\n",
      "Detected face: (388, 247, 595, 454)\n",
      "Detected: Trịnh Hửu Thọ, Box: (84, 128, 223, 267)\n",
      "Detected: Hoàng Manh Tường, Box: (388, 247, 595, 454)\n",
      "Detected face: (398, 246, 605, 453)\n",
      "Detected face: (104, 131, 246, 273)\n",
      "Detected: Quân Phan, Box: (398, 246, 605, 453)\n",
      "Detected: Hoàng Manh Tường, Box: (104, 131, 246, 273)\n",
      "Detected face: (110, 134, 259, 283)\n",
      "Detected face: (399, 246, 605, 452)\n",
      "Detected: Hoàng Manh Tường, Box: (110, 134, 259, 283)\n",
      "Detected: Quân Phan, Box: (399, 246, 605, 452)\n",
      "Detected face: (132, 150, 284, 302)\n",
      "Detected face: (394, 245, 601, 452)\n",
      "Detected: Quân Phan, Box: (132, 150, 284, 302)\n",
      "Detected: Quân Phan, Box: (394, 245, 601, 452)\n",
      "Detected face: (392, 244, 601, 453)\n",
      "Detected face: (133, 152, 288, 307)\n",
      "Detected: Quân Phan, Box: (392, 244, 601, 453)\n",
      "Detected: Quân Phan, Box: (133, 152, 288, 307)\n",
      "Detected face: (126, 154, 283, 311)\n",
      "Detected face: (389, 244, 599, 454)\n",
      "Detected: Quân Phan, Box: (126, 154, 283, 311)\n",
      "Detected: Quân Phan, Box: (389, 244, 599, 454)\n",
      "Detected face: (120, 159, 272, 311)\n",
      "Detected face: (389, 245, 598, 454)\n",
      "Detected: Hoàng Manh Tường, Box: (120, 159, 272, 311)\n",
      "Detected: Quân Phan, Box: (389, 245, 598, 454)\n",
      "Detected face: (116, 156, 266, 306)\n",
      "Detected face: (386, 242, 599, 455)\n",
      "Detected: Quân Phan, Box: (116, 156, 266, 306)\n",
      "Detected: Quân Phan, Box: (386, 242, 599, 455)\n",
      "Detected face: (386, 243, 595, 452)\n",
      "Detected face: (119, 157, 269, 307)\n",
      "Detected: Quân Phan, Box: (386, 243, 595, 452)\n",
      "Detected: Hoàng Manh Tường, Box: (119, 157, 269, 307)\n",
      "Detected face: (116, 151, 270, 305)\n",
      "Detected face: (385, 245, 590, 450)\n",
      "Detected: Quân Phan, Box: (116, 151, 270, 305)\n",
      "Detected: Quân Phan, Box: (385, 245, 590, 450)\n",
      "Detected face: (121, 152, 274, 305)\n",
      "Detected face: (385, 245, 590, 450)\n",
      "Detected: Quân Phan, Box: (121, 152, 274, 305)\n",
      "Detected: Quân Phan, Box: (385, 245, 590, 450)\n",
      "Detected face: (118, 151, 271, 304)\n",
      "Detected face: (383, 243, 592, 452)\n",
      "Detected: Quân Phan, Box: (118, 151, 271, 304)\n",
      "Detected: Quân Phan, Box: (383, 243, 592, 452)\n",
      "Detected face: (120, 151, 273, 304)\n",
      "Detected face: (385, 244, 593, 452)\n",
      "Detected: Quân Phan, Box: (120, 151, 273, 304)\n",
      "Detected: Quân Phan, Box: (385, 244, 593, 452)\n",
      "Detected face: (118, 149, 272, 303)\n",
      "Detected face: (385, 245, 593, 453)\n",
      "Detected: Quân Phan, Box: (118, 149, 272, 303)\n",
      "Detected: Quân Phan, Box: (385, 245, 593, 453)\n",
      "Detected face: (120, 151, 272, 303)\n",
      "Detected face: (386, 244, 592, 450)\n",
      "Detected: Quân Phan, Box: (120, 151, 272, 303)\n",
      "Detected: Quân Phan, Box: (386, 244, 592, 450)\n",
      "Detected face: (116, 147, 273, 304)\n",
      "Detected face: (385, 243, 593, 451)\n",
      "Detected: Quân Phan, Box: (116, 147, 273, 304)\n",
      "Detected: Quân Phan, Box: (385, 243, 593, 451)\n",
      "Detected face: (113, 146, 271, 304)\n",
      "Detected face: (384, 239, 589, 444)\n",
      "Detected: Quân Phan, Box: (113, 146, 271, 304)\n",
      "Detected: Quân Phan, Box: (384, 239, 589, 444)\n",
      "Detected face: (118, 147, 273, 302)\n",
      "Detected face: (387, 242, 586, 441)\n",
      "Detected: Quân Phan, Box: (118, 147, 273, 302)\n",
      "Detected: Quân Phan, Box: (387, 242, 586, 441)\n",
      "Detected face: (117, 146, 272, 301)\n",
      "Detected face: (381, 240, 587, 446)\n",
      "Detected: Hoàng Manh Tường, Box: (117, 146, 272, 301)\n",
      "Detected: Quân Phan, Box: (381, 240, 587, 446)\n",
      "Detected face: (127, 132, 273, 278)\n",
      "Detected face: (381, 237, 584, 440)\n",
      "Detected: Quân Phan, Box: (127, 132, 273, 278)\n",
      "Detected: Quân Phan, Box: (381, 237, 584, 440)\n",
      "Detected face: (379, 236, 584, 441)\n",
      "Detected face: (125, 131, 271, 277)\n",
      "Detected: Quân Phan, Box: (379, 236, 584, 441)\n",
      "Detected: Quân Phan, Box: (125, 131, 271, 277)\n",
      "Detected face: (385, 238, 589, 442)\n",
      "Detected face: (123, 128, 272, 277)\n",
      "Detected: Quân Phan, Box: (385, 238, 589, 442)\n",
      "Detected: Quân Phan, Box: (123, 128, 272, 277)\n",
      "Detected face: (123, 132, 268, 277)\n",
      "Detected face: (388, 235, 601, 448)\n",
      "Detected: Quân Phan, Box: (123, 132, 268, 277)\n",
      "Detected: Quân Phan, Box: (388, 235, 601, 448)\n",
      "Detected face: (387, 244, 592, 449)\n",
      "Detected face: (118, 151, 264, 297)\n",
      "Detected: Quân Phan, Box: (387, 244, 592, 449)\n",
      "Detected: Hoàng Manh Tường, Box: (118, 151, 264, 297)\n",
      "Detected face: (104, 142, 256, 294)\n",
      "Detected face: (388, 237, 598, 447)\n",
      "Detected: Quân Phan, Box: (104, 142, 256, 294)\n",
      "Detected: Quân Phan, Box: (388, 237, 598, 447)\n",
      "Detected face: (107, 148, 255, 296)\n",
      "Detected face: (383, 241, 591, 449)\n",
      "Detected: Quân Phan, Box: (107, 148, 255, 296)\n",
      "Detected: Quân Phan, Box: (383, 241, 591, 449)\n",
      "Detected face: (105, 147, 255, 297)\n",
      "Detected face: (383, 242, 591, 450)\n",
      "Detected: Quân Phan, Box: (105, 147, 255, 297)\n",
      "Detected: Quân Phan, Box: (383, 242, 591, 450)\n",
      "Detected face: (104, 146, 256, 298)\n",
      "Detected face: (390, 240, 596, 446)\n",
      "Detected: Quân Phan, Box: (104, 146, 256, 298)\n",
      "Detected: Quân Phan, Box: (390, 240, 596, 446)\n",
      "Detected face: (104, 147, 255, 298)\n",
      "Detected face: (388, 242, 590, 444)\n",
      "Detected: Quân Phan, Box: (104, 147, 255, 298)\n",
      "Detected: Quân Phan, Box: (388, 242, 590, 444)\n",
      "Detected face: (383, 242, 589, 448)\n",
      "Detected face: (105, 148, 255, 298)\n",
      "Detected: Quân Phan, Box: (383, 242, 589, 448)\n",
      "Detected: Quân Phan, Box: (105, 148, 255, 298)\n",
      "Detected face: (105, 147, 257, 299)\n",
      "Detected face: (382, 243, 588, 449)\n",
      "Detected: Quân Phan, Box: (105, 147, 257, 299)\n",
      "Detected: Quân Phan, Box: (382, 243, 588, 449)\n",
      "Detected face: (104, 146, 257, 299)\n",
      "Detected face: (384, 246, 587, 449)\n",
      "Detected: Quân Phan, Box: (104, 146, 257, 299)\n",
      "Detected: Quân Phan, Box: (384, 246, 587, 449)\n",
      "Detected face: (383, 244, 587, 448)\n",
      "Detected face: (105, 148, 256, 299)\n",
      "Detected: Quân Phan, Box: (383, 244, 587, 448)\n",
      "Detected: Quân Phan, Box: (105, 148, 256, 299)\n",
      "Detected face: (106, 150, 253, 297)\n",
      "Detected face: (382, 245, 588, 451)\n",
      "Detected: Quân Phan, Box: (106, 150, 253, 297)\n",
      "Detected: Quân Phan, Box: (382, 245, 588, 451)\n",
      "Detected face: (383, 245, 589, 451)\n",
      "Detected face: (107, 149, 256, 298)\n",
      "Detected: Quân Phan, Box: (383, 245, 589, 451)\n",
      "Detected: Quân Phan, Box: (107, 149, 256, 298)\n",
      "Detected face: (383, 245, 588, 450)\n",
      "Detected face: (108, 148, 257, 297)\n",
      "Detected: Quân Phan, Box: (383, 245, 588, 450)\n",
      "Detected: Quân Phan, Box: (108, 148, 257, 297)\n",
      "Detected face: (107, 148, 256, 297)\n",
      "Detected face: (386, 246, 589, 449)\n",
      "Detected: Quân Phan, Box: (107, 148, 256, 297)\n",
      "Detected: Quân Phan, Box: (386, 246, 589, 449)\n",
      "Detected face: (107, 149, 254, 296)\n",
      "Detected face: (384, 247, 585, 448)\n",
      "Detected: Quân Phan, Box: (107, 149, 254, 296)\n",
      "Detected: Quân Phan, Box: (384, 247, 585, 448)\n",
      "Detected face: (104, 146, 256, 298)\n",
      "Detected face: (390, 247, 594, 451)\n",
      "Detected: Quân Phan, Box: (104, 146, 256, 298)\n",
      "Detected: Quân Phan, Box: (390, 247, 594, 451)\n",
      "Detected face: (104, 137, 252, 285)\n",
      "Detected: Hoàng Manh Tường, Box: (104, 137, 252, 285)\n",
      "Detected face: (102, 128, 254, 280)\n",
      "Detected: Quân Phan, Box: (102, 128, 254, 280)\n",
      "Detected face: (101, 128, 255, 282)\n",
      "Detected: Quân Phan, Box: (101, 128, 255, 282)\n",
      "Detected face: (100, 131, 251, 282)\n",
      "Detected face: (350, 259, 555, 464)\n",
      "Detected: Hoàng Manh Tường, Box: (100, 131, 251, 282)\n",
      "Detected: Quân Phan, Box: (350, 259, 555, 464)\n",
      "Detected face: (99, 130, 250, 281)\n",
      "Detected face: (406, 249, 615, 458)\n",
      "Detected: Quân Phan, Box: (99, 130, 250, 281)\n",
      "Detected: Quân Phan, Box: (406, 249, 615, 458)\n",
      "Detected face: (100, 133, 251, 284)\n",
      "Detected face: (405, 250, 614, 459)\n",
      "Detected: Quân Phan, Box: (100, 133, 251, 284)\n",
      "Detected: Quân Phan, Box: (405, 250, 614, 459)\n",
      "Detected face: (97, 137, 251, 291)\n",
      "Detected face: (394, 247, 603, 456)\n",
      "Detected: Quân Phan, Box: (97, 137, 251, 291)\n",
      "Detected: Quân Phan, Box: (394, 247, 603, 456)\n",
      "Detected face: (390, 247, 601, 458)\n",
      "Detected face: (85, 142, 238, 295)\n",
      "Detected: Quân Phan, Box: (390, 247, 601, 458)\n",
      "Detected: Quân Phan, Box: (85, 142, 238, 295)\n",
      "Detected face: (48, 162, 220, 334)\n",
      "Detected face: (400, 297, 576, 473)\n",
      "Detected: Quân Phan, Box: (48, 162, 220, 334)\n",
      "Detected: Quân Phan, Box: (400, 297, 576, 473)\n",
      "Detected face: (70, 149, 261, 340)\n",
      "Detected face: (398, 283, 584, 469)\n",
      "Detected: Hoàng Manh Tường, Box: (70, 149, 261, 340)\n",
      "Detected: Quân Phan, Box: (398, 283, 584, 469)\n",
      "Detected face: (68, 136, 292, 360)\n",
      "Detected face: (395, 269, 589, 463)\n",
      "Detected: Quân Phan, Box: (68, 136, 292, 360)\n",
      "Detected: Quân Phan, Box: (395, 269, 589, 463)\n",
      "Detected face: (401, 270, 596, 465)\n",
      "Detected face: (30, 170, 265, 405)\n",
      "Detected: Quân Phan, Box: (401, 270, 596, 465)\n",
      "Detected: Hoàng Manh Tường, Box: (30, 170, 265, 405)\n",
      "Detected face: (403, 272, 598, 467)\n",
      "Detected face: (39, 161, 273, 395)\n",
      "Detected: Quân Phan, Box: (403, 272, 598, 467)\n",
      "Detected: Quân Phan, Box: (39, 161, 273, 395)\n",
      "Detected face: (408, 274, 603, 469)\n",
      "Detected face: (46, 154, 278, 386)\n",
      "Detected: Quân Phan, Box: (408, 274, 603, 469)\n",
      "Detected: Quân Phan, Box: (46, 154, 278, 386)\n",
      "Detected face: (39, 150, 274, 385)\n",
      "Detected face: (405, 270, 600, 465)\n",
      "Detected: Quân Phan, Box: (39, 150, 274, 385)\n",
      "Detected: Quân Phan, Box: (405, 270, 600, 465)\n",
      "Detected face: (406, 272, 598, 464)\n",
      "Detected face: (39, 148, 276, 385)\n",
      "Detected: Quân Phan, Box: (406, 272, 598, 464)\n",
      "Detected: Quân Phan, Box: (39, 148, 276, 385)\n",
      "Detected face: (404, 272, 600, 468)\n",
      "Detected face: (39, 151, 269, 381)\n",
      "Detected: Quân Phan, Box: (404, 272, 600, 468)\n",
      "Detected: Quân Phan, Box: (39, 151, 269, 381)\n",
      "Detected face: (403, 270, 601, 468)\n",
      "Detected face: (32, 154, 261, 383)\n",
      "Detected: Quân Phan, Box: (403, 270, 601, 468)\n",
      "Detected: Quân Phan, Box: (32, 154, 261, 383)\n",
      "Detected face: (35, 156, 261, 382)\n",
      "Detected face: (403, 271, 599, 467)\n",
      "Detected: Quân Phan, Box: (35, 156, 261, 382)\n",
      "Detected: Quân Phan, Box: (403, 271, 599, 467)\n",
      "Detected face: (36, 154, 264, 382)\n",
      "Detected face: (404, 272, 599, 467)\n",
      "Detected: Quân Phan, Box: (36, 154, 264, 382)\n",
      "Detected: Quân Phan, Box: (404, 272, 599, 467)\n",
      "Detected face: (403, 270, 598, 465)\n",
      "Detected face: (32, 149, 266, 383)\n",
      "Detected: Quân Phan, Box: (403, 270, 598, 465)\n",
      "Detected: Quân Phan, Box: (32, 149, 266, 383)\n",
      "Detected face: (403, 269, 597, 463)\n",
      "Detected face: (31, 150, 265, 384)\n",
      "Detected: Quân Phan, Box: (403, 269, 597, 463)\n",
      "Detected: Quân Phan, Box: (31, 150, 265, 384)\n",
      "Detected face: (401, 270, 596, 465)\n",
      "Detected face: (30, 151, 264, 385)\n",
      "Detected: Quân Phan, Box: (401, 270, 596, 465)\n",
      "Detected: Quân Phan, Box: (30, 151, 264, 385)\n",
      "Detected face: (388, 251, 593, 456)\n",
      "Detected face: (34, 151, 270, 387)\n",
      "Detected: Quân Phan, Box: (388, 251, 593, 456)\n",
      "Detected: Quân Phan, Box: (34, 151, 270, 387)\n",
      "Detected face: (369, 222, 593, 446)\n",
      "Detected face: (31, 153, 264, 386)\n",
      "Detected: Quân Phan, Box: (369, 222, 593, 446)\n",
      "Detected: Quân Phan, Box: (31, 153, 264, 386)\n",
      "Detected face: (25, 145, 258, 378)\n",
      "Detected face: (357, 209, 588, 440)\n",
      "Detected: Quân Phan, Box: (25, 145, 258, 378)\n",
      "Detected: Quân Phan, Box: (357, 209, 588, 440)\n",
      "Detected face: (32, 154, 257, 379)\n",
      "Detected face: (350, 205, 589, 444)\n",
      "Detected: Quân Phan, Box: (32, 154, 257, 379)\n",
      "Detected: Quân Phan, Box: (350, 205, 589, 444)\n",
      "Detected face: (29, 140, 245, 356)\n",
      "Detected face: (352, 210, 586, 444)\n",
      "Detected: Hoàng Manh Tường, Box: (29, 140, 245, 356)\n",
      "Detected: Quân Phan, Box: (352, 210, 586, 444)\n",
      "Detected face: (10, 119, 222, 331)\n",
      "Detected face: (361, 221, 590, 450)\n",
      "Detected: Quân Phan, Box: (10, 119, 222, 331)\n",
      "Detected: Quân Phan, Box: (361, 221, 590, 450)\n",
      "Detected face: (7, 118, 207, 318)\n",
      "Detected: Hoàng Manh Tường, Box: (7, 118, 207, 318)\n",
      "Detected face: (9, 119, 207, 317)\n",
      "Detected: Trịnh Hửu Thọ, Box: (9, 119, 207, 317)\n",
      "Detected face: (7, 115, 209, 317)\n",
      "Detected: Hoàng Manh Tường, Box: (7, 115, 209, 317)\n",
      "Detected face: (11, 121, 214, 324)\n",
      "Detected: Hoàng Manh Tường, Box: (11, 121, 214, 324)\n",
      "Detected face: (5, 134, 194, 323)\n",
      "Detected: Hoàng Manh Tường, Box: (5, 134, 194, 323)\n",
      "Detected face: (366, 180, 477, 291)\n",
      "Detected: Quân Phan, Box: (366, 180, 477, 291)\n",
      "Detected face: (365, 179, 476, 290)\n",
      "Detected: Quân Phan, Box: (365, 179, 476, 290)\n",
      "Detected face: (10, 151, 188, 329)\n",
      "Detected face: (168, 36, 277, 145)\n",
      "Detected: Hoàng Manh Tường, Box: (10, 151, 188, 329)\n",
      "Detected: Quân Phan, Box: (168, 36, 277, 145)\n",
      "Detected face: (80, 162, 282, 364)\n",
      "Detected: Hoàng Manh Tường, Box: (80, 162, 282, 364)\n",
      "Detected face: (86, 170, 302, 386)\n",
      "Detected: Quân Phan, Box: (86, 170, 302, 386)\n",
      "Detected face: (84, 176, 297, 389)\n",
      "Detected: Quân Phan, Box: (84, 176, 297, 389)\n",
      "Detected face: (75, 184, 282, 391)\n",
      "Detected: Quân Phan, Box: (75, 184, 282, 391)\n",
      "Detected face: (76, 178, 287, 389)\n",
      "Detected: Quân Phan, Box: (76, 178, 287, 389)\n",
      "Detected face: (76, 179, 284, 387)\n",
      "Detected: Quân Phan, Box: (76, 179, 284, 387)\n",
      "Detected face: (73, 170, 277, 374)\n",
      "Detected: Quân Phan, Box: (73, 170, 277, 374)\n",
      "Detected face: (66, 158, 273, 365)\n",
      "Detected: Quân Phan, Box: (66, 158, 273, 365)\n",
      "Detected face: (61, 140, 275, 354)\n",
      "Detected: Quân Phan, Box: (61, 140, 275, 354)\n",
      "Detected face: (62, 139, 276, 353)\n",
      "Detected: Quân Phan, Box: (62, 139, 276, 353)\n",
      "Detected face: (58, 139, 276, 357)\n",
      "Detected: Quân Phan, Box: (58, 139, 276, 357)\n",
      "Detected face: (61, 140, 276, 355)\n",
      "Detected: Quân Phan, Box: (61, 140, 276, 355)\n",
      "Detected face: (62, 141, 275, 354)\n",
      "Detected: Quân Phan, Box: (62, 141, 275, 354)\n",
      "Detected face: (62, 143, 273, 354)\n",
      "Detected: Quân Phan, Box: (62, 143, 273, 354)\n",
      "Detected face: (58, 142, 275, 359)\n",
      "Detected: Quân Phan, Box: (58, 142, 275, 359)\n",
      "Detected face: (57, 139, 279, 361)\n",
      "Detected: Quân Phan, Box: (57, 139, 279, 361)\n",
      "Detected face: (63, 142, 282, 361)\n",
      "Detected: Quân Phan, Box: (63, 142, 282, 361)\n",
      "Detected face: (54, 141, 276, 363)\n",
      "Detected: Quân Phan, Box: (54, 141, 276, 363)\n",
      "Detected face: (10, 153, 217, 360)\n",
      "Detected: Hoàng Manh Tường, Box: (10, 153, 217, 360)\n",
      "Detected face: (376, 276, 574, 474)\n",
      "Detected: Hoàng Manh Tường, Box: (376, 276, 574, 474)\n",
      "Detected face: (5, 170, 195, 360)\n",
      "Detected face: (357, 285, 544, 472)\n",
      "Detected: Quân Phan, Box: (5, 170, 195, 360)\n",
      "Detected: Quân Phan, Box: (357, 285, 544, 472)\n",
      "Detected face: (359, 287, 543, 471)\n",
      "Detected: Quân Phan, Box: (359, 287, 543, 471)\n",
      "Detected face: (352, 290, 538, 476)\n",
      "Detected: Hoàng Manh Tường, Box: (352, 290, 538, 476)\n",
      "Detected face: (8, 9, 145, 146)\n",
      "Detected: Trịnh Hửu Thọ, Box: (8, 9, 145, 146)\n",
      "Detected face: (10, 10, 147, 147)\n",
      "Detected face: (316, 296, 496, 476)\n",
      "Detected: Trịnh Hửu Thọ, Box: (10, 10, 147, 147)\n",
      "Detected: Hoàng Manh Tường, Box: (316, 296, 496, 476)\n",
      "Detected face: (291, 296, 467, 472)\n",
      "Detected: Quân Phan, Box: (291, 296, 467, 472)\n",
      "Detected face: (295, 297, 471, 473)\n",
      "Detected: Hoàng Manh Tường, Box: (295, 297, 471, 473)\n",
      "Detected face: (228, 88, 290, 150)\n",
      "Detected: Trịnh Hửu Thọ, Box: (228, 88, 290, 150)\n",
      "Detected face: (230, 90, 291, 151)\n",
      "Detected: Trịnh Hửu Thọ, Box: (230, 90, 291, 151)\n",
      "Detected face: (336, 194, 564, 422)\n",
      "Detected face: (206, 40, 257, 91)\n",
      "Detected: Quân Phan, Box: (336, 194, 564, 422)\n",
      "Detected: Quân Phan, Box: (206, 40, 257, 91)\n",
      "Detected face: (210, 32, 263, 85)\n",
      "Detected: Quân Phan, Box: (210, 32, 263, 85)\n",
      "Detected face: (212, 31, 267, 86)\n",
      "Detected face: (336, 200, 564, 428)\n",
      "Detected: Quân Phan, Box: (212, 31, 267, 86)\n",
      "Detected: Quân Phan, Box: (336, 200, 564, 428)\n",
      "Detected face: (337, 201, 561, 425)\n",
      "Detected face: (218, 34, 270, 86)\n",
      "Detected: Quân Phan, Box: (337, 201, 561, 425)\n",
      "Detected: Hoàng Manh Tường, Box: (218, 34, 270, 86)\n",
      "Detected face: (217, 32, 271, 86)\n",
      "Detected face: (335, 200, 561, 426)\n",
      "Detected: Hoàng Manh Tường, Box: (217, 32, 271, 86)\n",
      "Detected: Quân Phan, Box: (335, 200, 561, 426)\n",
      "Detected face: (219, 38, 266, 85)\n",
      "Detected face: (339, 201, 567, 429)\n",
      "Detected: Hoàng Manh Tường, Box: (219, 38, 266, 85)\n",
      "Detected: Quân Phan, Box: (339, 201, 567, 429)\n",
      "Detected face: (212, 30, 267, 85)\n",
      "Detected: Quân Phan, Box: (212, 30, 267, 85)\n",
      "Detected face: (209, 30, 264, 85)\n",
      "Detected: Hoàng Manh Tường, Box: (209, 30, 264, 85)\n",
      "Detected face: (212, 32, 263, 83)\n",
      "Detected: Hoàng Manh Tường, Box: (212, 32, 263, 83)\n",
      "Detected face: (334, 10, 555, 231)\n",
      "Detected: Hoàng Manh Tường, Box: (334, 10, 555, 231)\n",
      "Detected face: (305, 118, 506, 319)\n",
      "Detected: Quân Phan, Box: (305, 118, 506, 319)\n",
      "Detected face: (29, 79, 136, 186)\n",
      "Detected face: (277, 287, 456, 466)\n",
      "Detected: Trịnh Hửu Thọ, Box: (29, 79, 136, 186)\n",
      "Detected: Quân Phan, Box: (277, 287, 456, 466)\n",
      "Detected face: (275, 260, 461, 446)\n",
      "Detected: Quân Phan, Box: (275, 260, 461, 446)\n",
      "Detected face: (258, 252, 444, 438)\n",
      "Detected: Hoàng Manh Tường, Box: (258, 252, 444, 438)\n",
      "Detected face: (250, 254, 443, 447)\n",
      "Detected: Quân Phan, Box: (250, 254, 443, 447)\n",
      "Detected face: (250, 250, 449, 449)\n",
      "Detected: Quân Phan, Box: (250, 250, 449, 449)\n",
      "Detected face: (252, 250, 451, 449)\n",
      "Detected: Quân Phan, Box: (252, 250, 451, 449)\n",
      "Detected face: (251, 252, 451, 452)\n",
      "Detected: Quân Phan, Box: (251, 252, 451, 452)\n",
      "Detected face: (253, 254, 448, 449)\n",
      "Detected: Quân Phan, Box: (253, 254, 448, 449)\n",
      "Detected face: (13, 64, 119, 170)\n",
      "Detected face: (255, 258, 447, 450)\n",
      "Detected face: (113, 290, 191, 368)\n",
      "Detected: Trịnh Hửu Thọ, Box: (13, 64, 119, 170)\n",
      "Detected: Quân Phan, Box: (255, 258, 447, 450)\n",
      "Detected: Quân Phan, Box: (113, 290, 191, 368)\n",
      "Detected face: (20, 64, 128, 172)\n",
      "Detected face: (251, 258, 445, 452)\n",
      "Detected: Trịnh Hửu Thọ, Box: (20, 64, 128, 172)\n",
      "Detected: Quân Phan, Box: (251, 258, 445, 452)\n",
      "Detected face: (18, 69, 131, 182)\n",
      "Detected face: (284, 256, 482, 454)\n",
      "Detected: Trịnh Hửu Thọ, Box: (18, 69, 131, 182)\n",
      "Detected: Quân Phan, Box: (284, 256, 482, 454)\n",
      "Detected face: (294, 263, 499, 468)\n",
      "Detected: Hoàng Manh Tường, Box: (294, 263, 499, 468)\n",
      "Detected face: (270, 263, 465, 458)\n",
      "Detected face: (83, 285, 170, 372)\n",
      "Detected: Quân Phan, Box: (270, 263, 465, 458)\n",
      "Detected: Quân Phan, Box: (83, 285, 170, 372)\n",
      "Detected face: (245, 272, 437, 464)\n",
      "Detected: Quân Phan, Box: (245, 272, 437, 464)\n",
      "Detected face: (224, 267, 430, 473)\n",
      "Detected: Quân Phan, Box: (224, 267, 430, 473)\n",
      "Detected face: (183, 221, 428, 466)\n",
      "Detected: Quân Phan, Box: (183, 221, 428, 466)\n",
      "Detected face: (162, 202, 421, 461)\n",
      "Detected: Quân Phan, Box: (162, 202, 421, 461)\n",
      "Detected face: (116, 162, 420, 466)\n",
      "Detected: Quân Phan, Box: (116, 162, 420, 466)\n",
      "Detected face: (132, 166, 429, 463)\n",
      "Detected: Quân Phan, Box: (132, 166, 429, 463)\n",
      "Detected face: (196, 179, 461, 444)\n",
      "Detected: Quân Phan, Box: (196, 179, 461, 444)\n",
      "Detected face: (235, 209, 452, 426)\n",
      "Detected: Quân Phan, Box: (235, 209, 452, 426)\n",
      "Detected face: (239, 213, 447, 421)\n",
      "Detected: Quân Phan, Box: (239, 213, 447, 421)\n",
      "Detected face: (90, 37, 214, 161)\n",
      "Detected face: (236, 208, 445, 417)\n",
      "Detected: Trịnh Hửu Thọ, Box: (90, 37, 214, 161)\n",
      "Detected: Quân Phan, Box: (236, 208, 445, 417)\n",
      "Detected face: (159, 19, 285, 145)\n",
      "Detected face: (239, 216, 448, 425)\n",
      "Detected: Quân Phan, Box: (159, 19, 285, 145)\n",
      "Detected: Quân Phan, Box: (239, 216, 448, 425)\n",
      "Detected face: (142, 31, 265, 154)\n",
      "Detected face: (228, 171, 445, 388)\n",
      "Detected: Quân Phan, Box: (142, 31, 265, 154)\n",
      "Detected: Quân Phan, Box: (228, 171, 445, 388)\n",
      "Detected face: (128, 38, 248, 158)\n",
      "Detected face: (193, 141, 455, 403)\n",
      "Detected: Quân Phan, Box: (128, 38, 248, 158)\n",
      "Detected: Quân Phan, Box: (193, 141, 455, 403)\n",
      "Detected face: (115, 43, 234, 162)\n",
      "Detected face: (209, 175, 442, 408)\n",
      "Detected: Quân Phan, Box: (115, 43, 234, 162)\n",
      "Detected: Quân Phan, Box: (209, 175, 442, 408)\n",
      "Detected face: (120, 47, 240, 167)\n",
      "Detected face: (231, 192, 436, 397)\n",
      "Detected: Quân Phan, Box: (120, 47, 240, 167)\n",
      "Detected: Quân Phan, Box: (231, 192, 436, 397)\n",
      "Detected face: (125, 46, 247, 168)\n",
      "Detected face: (238, 200, 438, 400)\n",
      "Detected: Quân Phan, Box: (125, 46, 247, 168)\n",
      "Detected: Quân Phan, Box: (238, 200, 438, 400)\n",
      "Detected face: (130, 48, 251, 169)\n",
      "Detected face: (208, 284, 283, 359)\n",
      "Detected face: (259, 215, 460, 416)\n",
      "Detected: Quân Phan, Box: (130, 48, 251, 169)\n",
      "Detected: Trịnh Hửu Thọ, Box: (208, 284, 283, 359)\n",
      "Detected: Quân Phan, Box: (259, 215, 460, 416)\n",
      "Detected face: (131, 45, 253, 167)\n",
      "Detected face: (270, 216, 470, 416)\n",
      "Detected: Quân Phan, Box: (131, 45, 253, 167)\n",
      "Detected: Quân Phan, Box: (270, 216, 470, 416)\n",
      "Detected face: (132, 48, 251, 167)\n",
      "Detected face: (208, 281, 289, 362)\n",
      "Detected face: (270, 214, 476, 420)\n",
      "Detected: Quân Phan, Box: (132, 48, 251, 167)\n",
      "Detected: Trịnh Hửu Thọ, Box: (208, 281, 289, 362)\n",
      "Detected: Quân Phan, Box: (270, 214, 476, 420)\n",
      "Detected face: (135, 47, 253, 165)\n",
      "Detected face: (204, 279, 291, 366)\n",
      "Detected face: (268, 216, 470, 418)\n",
      "Detected: Quân Phan, Box: (135, 47, 253, 165)\n",
      "Detected: Trịnh Hửu Thọ, Box: (204, 279, 291, 366)\n",
      "Detected: Quân Phan, Box: (268, 216, 470, 418)\n",
      "Detected face: (137, 46, 256, 165)\n",
      "Detected face: (268, 217, 471, 420)\n",
      "Detected: Quân Phan, Box: (137, 46, 256, 165)\n",
      "Detected: Quân Phan, Box: (268, 217, 471, 420)\n",
      "Detected face: (138, 47, 253, 162)\n",
      "Detected face: (272, 220, 466, 414)\n",
      "Detected: Quân Phan, Box: (138, 47, 253, 162)\n",
      "Detected: Quân Phan, Box: (272, 220, 466, 414)\n",
      "Detected face: (136, 47, 252, 163)\n",
      "Detected face: (269, 218, 470, 419)\n",
      "Detected: Quân Phan, Box: (136, 47, 252, 163)\n",
      "Detected: Quân Phan, Box: (269, 218, 470, 419)\n",
      "Detected face: (137, 47, 253, 163)\n",
      "Detected face: (269, 219, 471, 421)\n",
      "Detected face: (206, 280, 287, 361)\n",
      "Detected: Quân Phan, Box: (137, 47, 253, 163)\n",
      "Detected: Quân Phan, Box: (269, 219, 471, 421)\n",
      "Detected: Quân Phan, Box: (206, 280, 287, 361)\n",
      "Detected face: (134, 45, 251, 162)\n",
      "Detected face: (203, 279, 285, 361)\n",
      "Detected face: (268, 217, 472, 421)\n",
      "Detected: Quân Phan, Box: (134, 45, 251, 162)\n",
      "Detected: Trịnh Hửu Thọ, Box: (203, 279, 285, 361)\n",
      "Detected: Quân Phan, Box: (268, 217, 472, 421)\n",
      "Detected face: (131, 39, 250, 158)\n",
      "Detected face: (266, 219, 467, 420)\n",
      "Detected: Quân Phan, Box: (131, 39, 250, 158)\n",
      "Detected: Quân Phan, Box: (266, 219, 467, 420)\n",
      "Detected face: (130, 40, 250, 160)\n",
      "Detected face: (265, 216, 469, 420)\n",
      "Detected: Quân Phan, Box: (130, 40, 250, 160)\n",
      "Detected: Quân Phan, Box: (265, 216, 469, 420)\n",
      "Detected face: (131, 41, 250, 160)\n",
      "Detected face: (266, 216, 469, 419)\n",
      "Detected: Quân Phan, Box: (131, 41, 250, 160)\n",
      "Detected: Quân Phan, Box: (266, 216, 469, 419)\n",
      "Detected face: (122, 44, 239, 161)\n",
      "Detected face: (264, 215, 469, 420)\n",
      "Detected: Quân Phan, Box: (122, 44, 239, 161)\n",
      "Detected: Quân Phan, Box: (264, 215, 469, 420)\n",
      "Detected face: (99, 43, 218, 162)\n",
      "Detected face: (183, 290, 256, 363)\n",
      "Detected face: (262, 215, 463, 416)\n",
      "Detected: Trịnh Hửu Thọ, Box: (99, 43, 218, 162)\n",
      "Detected: Trịnh Hửu Thọ, Box: (183, 290, 256, 363)\n",
      "Detected: Quân Phan, Box: (262, 215, 463, 416)\n",
      "Detected face: (110, 68, 214, 172)\n",
      "Detected face: (268, 217, 465, 414)\n",
      "Detected: Trịnh Hửu Thọ, Box: (110, 68, 214, 172)\n",
      "Detected: Quân Phan, Box: (268, 217, 465, 414)\n",
      "Detected face: (147, 83, 251, 187)\n",
      "Detected face: (271, 219, 465, 413)\n",
      "Detected: Quân Phan, Box: (147, 83, 251, 187)\n",
      "Detected: Quân Phan, Box: (271, 219, 465, 413)\n",
      "Detected face: (76, 95, 167, 186)\n",
      "Detected face: (272, 218, 469, 415)\n",
      "Detected: Trịnh Hửu Thọ, Box: (76, 95, 167, 186)\n",
      "Detected: Quân Phan, Box: (272, 218, 469, 415)\n",
      "Detected face: (269, 216, 470, 417)\n",
      "Detected: Quân Phan, Box: (269, 216, 470, 417)\n",
      "Detected face: (268, 216, 468, 416)\n",
      "Detected: Quân Phan, Box: (268, 216, 468, 416)\n",
      "Detected face: (269, 217, 467, 415)\n",
      "Detected: Quân Phan, Box: (269, 217, 467, 415)\n",
      "Detected face: (268, 216, 468, 416)\n",
      "Detected: Quân Phan, Box: (268, 216, 468, 416)\n",
      "Detected face: (269, 216, 471, 418)\n",
      "Detected: Quân Phan, Box: (269, 216, 471, 418)\n",
      "Detected face: (274, 216, 470, 412)\n",
      "Detected: Quân Phan, Box: (274, 216, 470, 412)\n",
      "Detected face: (262, 211, 461, 410)\n",
      "Detected: Quân Phan, Box: (262, 211, 461, 410)\n",
      "Detected face: (516, 325, 570, 379)\n",
      "Detected face: (253, 210, 451, 408)\n",
      "Detected: Trịnh Hửu Thọ, Box: (516, 325, 570, 379)\n",
      "Detected: Quân Phan, Box: (253, 210, 451, 408)\n",
      "Detected face: (520, 329, 573, 382)\n",
      "Detected face: (237, 207, 439, 409)\n",
      "Detected: Trịnh Hửu Thọ, Box: (520, 329, 573, 382)\n",
      "Detected: Quân Phan, Box: (237, 207, 439, 409)\n",
      "Detected face: (520, 329, 573, 382)\n",
      "Detected face: (231, 209, 434, 412)\n",
      "Detected: Trịnh Hửu Thọ, Box: (520, 329, 573, 382)\n",
      "Detected: Quân Phan, Box: (231, 209, 434, 412)\n",
      "Detected face: (521, 331, 573, 383)\n",
      "Detected face: (222, 209, 420, 407)\n",
      "Detected: Trịnh Hửu Thọ, Box: (521, 331, 573, 383)\n",
      "Detected: Quân Phan, Box: (222, 209, 420, 407)\n",
      "Detected face: (520, 331, 573, 384)\n",
      "Detected face: (220, 208, 419, 407)\n",
      "Detected: Trịnh Hửu Thọ, Box: (520, 331, 573, 384)\n",
      "Detected: Quân Phan, Box: (220, 208, 419, 407)\n",
      "Detected face: (519, 327, 574, 382)\n",
      "Detected face: (216, 212, 412, 408)\n",
      "Detected: Trịnh Hửu Thọ, Box: (519, 327, 574, 382)\n",
      "Detected: Quân Phan, Box: (216, 212, 412, 408)\n",
      "Detected face: (522, 331, 574, 383)\n",
      "Detected face: (215, 215, 409, 409)\n",
      "Detected: Trịnh Hửu Thọ, Box: (522, 331, 574, 383)\n",
      "Detected: Quân Phan, Box: (215, 215, 409, 409)\n",
      "Detected face: (213, 216, 408, 411)\n",
      "Detected: Quân Phan, Box: (213, 216, 408, 411)\n",
      "Detected face: (522, 333, 573, 384)\n",
      "Detected face: (214, 218, 407, 411)\n",
      "Detected: Trịnh Hửu Thọ, Box: (522, 333, 573, 384)\n",
      "Detected: Quân Phan, Box: (214, 218, 407, 411)\n",
      "Detected face: (208, 220, 402, 414)\n",
      "Detected face: (521, 331, 576, 386)\n",
      "Detected: Quân Phan, Box: (208, 220, 402, 414)\n",
      "Detected: Trịnh Hửu Thọ, Box: (521, 331, 576, 386)\n",
      "Detected face: (180, 219, 377, 416)\n",
      "Detected: Quân Phan, Box: (180, 219, 377, 416)\n",
      "Detected face: (526, 337, 572, 383)\n",
      "Detected face: (179, 219, 377, 417)\n",
      "Detected: Trịnh Hửu Thọ, Box: (526, 337, 572, 383)\n",
      "Detected: Quân Phan, Box: (179, 219, 377, 417)\n",
      "Detected face: (242, 131, 309, 198)\n",
      "Detected face: (522, 332, 575, 385)\n",
      "Detected face: (181, 216, 385, 420)\n",
      "Detected: Quân Phan, Box: (242, 131, 309, 198)\n",
      "Detected: Trịnh Hửu Thọ, Box: (522, 332, 575, 385)\n",
      "Detected: Quân Phan, Box: (181, 216, 385, 420)\n",
      "Detected face: (522, 330, 578, 386)\n",
      "Detected face: (210, 212, 407, 409)\n",
      "Detected: Quân Phan, Box: (522, 330, 578, 386)\n",
      "Detected: Quân Phan, Box: (210, 212, 407, 409)\n",
      "Detected face: (230, 207, 428, 405)\n",
      "Detected: Quân Phan, Box: (230, 207, 428, 405)\n",
      "Detected face: (123, 108, 225, 210)\n",
      "Detected: Trịnh Hửu Thọ, Box: (123, 108, 225, 210)\n",
      "Detected face: (141, 220, 230, 309)\n",
      "Detected face: (104, 65, 230, 191)\n",
      "Detected: Trịnh Hửu Thọ, Box: (141, 220, 230, 309)\n",
      "Detected: Hoàng Manh Tường, Box: (104, 65, 230, 191)\n",
      "Detected face: (44, 156, 178, 290)\n",
      "Detected: Quân Phan, Box: (44, 156, 178, 290)\n",
      "Detected face: (100, 314, 213, 427)\n",
      "Detected face: (89, 167, 212, 290)\n",
      "Detected: Quân Phan, Box: (100, 314, 213, 427)\n",
      "Detected: Quân Phan, Box: (89, 167, 212, 290)\n",
      "Detected face: (171, 337, 246, 412)\n",
      "Detected face: (142, 174, 263, 295)\n",
      "Detected: Quân Phan, Box: (171, 337, 246, 412)\n",
      "Detected: Hoàng Manh Tường, Box: (142, 174, 263, 295)\n",
      "Detected face: (178, 344, 258, 424)\n",
      "Detected face: (158, 186, 273, 301)\n",
      "Detected: Quân Phan, Box: (178, 344, 258, 424)\n",
      "Detected: Hoàng Manh Tường, Box: (158, 186, 273, 301)\n",
      "Detected face: (163, 188, 272, 297)\n",
      "Detected face: (177, 343, 257, 423)\n",
      "Detected: Hoàng Manh Tường, Box: (163, 188, 272, 297)\n",
      "Detected: Quân Phan, Box: (177, 343, 257, 423)\n",
      "Detected face: (183, 344, 261, 422)\n",
      "Detected face: (172, 189, 279, 296)\n",
      "Detected: Quân Phan, Box: (183, 344, 261, 422)\n",
      "Detected: Quân Phan, Box: (172, 189, 279, 296)\n",
      "Detected face: (184, 339, 260, 415)\n",
      "Detected face: (169, 180, 281, 292)\n",
      "Detected: Quân Phan, Box: (184, 339, 260, 415)\n",
      "Detected: Quân Phan, Box: (169, 180, 281, 292)\n",
      "Detected face: (160, 159, 275, 274)\n",
      "Detected face: (178, 320, 254, 396)\n",
      "Detected: Quân Phan, Box: (160, 159, 275, 274)\n",
      "Detected: Quân Phan, Box: (178, 320, 254, 396)\n",
      "Detected face: (125, 142, 245, 262)\n",
      "Detected face: (139, 310, 225, 396)\n",
      "Detected: Hoàng Manh Tường, Box: (125, 142, 245, 262)\n",
      "Detected: Trịnh Hửu Thọ, Box: (139, 310, 225, 396)\n",
      "Detected face: (107, 144, 228, 265)\n",
      "Detected face: (123, 319, 206, 402)\n",
      "Detected: Quân Phan, Box: (107, 144, 228, 265)\n",
      "Detected: Quân Phan, Box: (123, 319, 206, 402)\n",
      "Detected face: (117, 334, 199, 416)\n",
      "Detected face: (95, 153, 224, 282)\n",
      "Detected: Quân Phan, Box: (117, 334, 199, 416)\n",
      "Detected: Quân Phan, Box: (95, 153, 224, 282)\n",
      "Detected face: (115, 335, 201, 421)\n",
      "Detected face: (95, 153, 222, 280)\n",
      "Detected: Quân Phan, Box: (115, 335, 201, 421)\n",
      "Detected: Quân Phan, Box: (95, 153, 222, 280)\n",
      "Detected face: (92, 150, 227, 285)\n",
      "Detected face: (96, 302, 244, 450)\n",
      "Detected: Quân Phan, Box: (92, 150, 227, 285)\n",
      "Detected: Quân Phan, Box: (96, 302, 244, 450)\n",
      "Detected face: (106, 321, 213, 428)\n",
      "Detected face: (86, 151, 222, 287)\n",
      "Detected: Quân Phan, Box: (106, 321, 213, 428)\n",
      "Detected: Quân Phan, Box: (86, 151, 222, 287)\n",
      "Detected face: (119, 328, 207, 416)\n",
      "Detected face: (91, 148, 229, 286)\n",
      "Detected: Quân Phan, Box: (119, 328, 207, 416)\n",
      "Detected: Quân Phan, Box: (91, 148, 229, 286)\n",
      "Detected face: (111, 323, 211, 423)\n",
      "Detected face: (91, 149, 226, 284)\n",
      "Detected: Quân Phan, Box: (111, 323, 211, 423)\n",
      "Detected: Quân Phan, Box: (91, 149, 226, 284)\n",
      "Detected face: (113, 313, 233, 433)\n",
      "Detected face: (90, 150, 231, 291)\n",
      "Detected: Quân Phan, Box: (113, 313, 233, 433)\n",
      "Detected: Quân Phan, Box: (90, 150, 231, 291)\n",
      "Detected face: (122, 328, 212, 418)\n",
      "Detected face: (90, 154, 226, 290)\n",
      "Detected: Quân Phan, Box: (122, 328, 212, 418)\n",
      "Detected: Quân Phan, Box: (90, 154, 226, 290)\n",
      "Detected face: (117, 319, 221, 423)\n",
      "Detected face: (92, 157, 225, 290)\n",
      "Detected: Quân Phan, Box: (117, 319, 221, 423)\n",
      "Detected: Quân Phan, Box: (92, 157, 225, 290)\n",
      "Detected face: (120, 314, 238, 432)\n",
      "Detected face: (97, 156, 232, 291)\n",
      "Detected: Quân Phan, Box: (120, 314, 238, 432)\n",
      "Detected: Quân Phan, Box: (97, 156, 232, 291)\n",
      "Detected face: (120, 311, 235, 426)\n",
      "Detected face: (97, 152, 231, 286)\n",
      "Detected: Quân Phan, Box: (120, 311, 235, 426)\n",
      "Detected: Quân Phan, Box: (97, 152, 231, 286)\n",
      "Detected face: (120, 310, 233, 423)\n",
      "Detected face: (100, 151, 230, 281)\n",
      "Detected: Quân Phan, Box: (120, 310, 233, 423)\n",
      "Detected: Quân Phan, Box: (100, 151, 230, 281)\n",
      "Detected face: (116, 323, 220, 427)\n",
      "Detected face: (90, 148, 229, 287)\n",
      "Detected: Quân Phan, Box: (116, 323, 220, 427)\n",
      "Detected: Quân Phan, Box: (90, 148, 229, 287)\n",
      "Detected face: (148, 335, 237, 424)\n",
      "Detected face: (108, 154, 240, 286)\n",
      "Detected: Trịnh Hửu Thọ, Box: (148, 335, 237, 424)\n",
      "Detected: Hoàng Manh Tường, Box: (108, 154, 240, 286)\n",
      "Detected face: (146, 376, 237, 467)\n",
      "Detected face: (84, 188, 229, 333)\n",
      "Detected: Quân Phan, Box: (146, 376, 237, 467)\n",
      "Detected: Hoàng Manh Tường, Box: (84, 188, 229, 333)\n",
      "Detected face: (62, 194, 217, 349)\n",
      "Detected: Hoàng Manh Tường, Box: (62, 194, 217, 349)\n",
      "Detected face: (21, 166, 181, 326)\n",
      "Detected: Quân Phan, Box: (21, 166, 181, 326)\n",
      "Detected face: (14, 150, 178, 314)\n",
      "Detected: Quân Phan, Box: (14, 150, 178, 314)\n",
      "Detected face: (24, 140, 190, 306)\n",
      "Detected: Quân Phan, Box: (24, 140, 190, 306)\n",
      "Detected face: (75, 344, 188, 457)\n",
      "Detected face: (26, 132, 197, 303)\n",
      "Detected: Quân Phan, Box: (75, 344, 188, 457)\n",
      "Detected: Quân Phan, Box: (26, 132, 197, 303)\n",
      "Detected face: (42, 124, 206, 288)\n",
      "Detected face: (84, 331, 198, 445)\n",
      "Detected: Hoàng Manh Tường, Box: (42, 124, 206, 288)\n",
      "Detected: Trịnh Hửu Thọ, Box: (84, 331, 198, 445)\n",
      "Detected face: (94, 330, 210, 446)\n",
      "Detected face: (33, 128, 202, 297)\n",
      "Detected: Quân Phan, Box: (94, 330, 210, 446)\n",
      "Detected: Hoàng Manh Tường, Box: (33, 128, 202, 297)\n",
      "Detected face: (49, 129, 215, 295)\n",
      "Detected face: (101, 331, 216, 446)\n",
      "Detected: Hoàng Manh Tường, Box: (49, 129, 215, 295)\n",
      "Detected: Quân Phan, Box: (101, 331, 216, 446)\n",
      "Detected face: (66, 125, 233, 292)\n",
      "Detected face: (91, 323, 214, 446)\n",
      "Detected: Hoàng Manh Tường, Box: (66, 125, 233, 292)\n",
      "Detected: Quân Phan, Box: (91, 323, 214, 446)\n",
      "Detected face: (75, 120, 239, 284)\n",
      "Detected face: (108, 328, 211, 431)\n",
      "Detected face: (81, 298, 254, 471)\n",
      "Detected: Hoàng Manh Tường, Box: (75, 120, 239, 284)\n",
      "Detected: Quân Phan, Box: (108, 328, 211, 431)\n",
      "Detected: Quân Phan, Box: (81, 298, 254, 471)\n",
      "Detected face: (134, 169, 315, 350)\n",
      "Detected: Hoàng Manh Tường, Box: (134, 169, 315, 350)\n",
      "Detected face: (155, 190, 339, 374)\n",
      "Detected: Quân Phan, Box: (155, 190, 339, 374)\n",
      "Detected face: (146, 188, 331, 373)\n",
      "Detected: Quân Phan, Box: (146, 188, 331, 373)\n",
      "Detected face: (150, 183, 330, 363)\n",
      "Detected: Quân Phan, Box: (150, 183, 330, 363)\n",
      "Detected face: (148, 181, 329, 362)\n",
      "Detected: Quân Phan, Box: (148, 181, 329, 362)\n",
      "Detected face: (145, 178, 330, 363)\n",
      "Detected: Quân Phan, Box: (145, 178, 330, 363)\n",
      "Detected face: (151, 177, 331, 357)\n",
      "Detected: Quân Phan, Box: (151, 177, 331, 357)\n",
      "Detected face: (148, 165, 330, 347)\n",
      "Detected: Quân Phan, Box: (148, 165, 330, 347)\n",
      "Detected face: (140, 159, 320, 339)\n",
      "Detected: Quân Phan, Box: (140, 159, 320, 339)\n",
      "Detected face: (130, 155, 304, 329)\n",
      "Detected: Hoàng Manh Tường, Box: (130, 155, 304, 329)\n",
      "Detected face: (175, 53, 298, 176)\n",
      "Detected: Trịnh Hửu Thọ, Box: (175, 53, 298, 176)\n",
      "Detected face: (96, 90, 228, 222)\n",
      "Detected: Trịnh Hửu Thọ, Box: (96, 90, 228, 222)\n",
      "Detected face: (318, 308, 480, 470)\n",
      "Detected: Trịnh Hửu Thọ, Box: (318, 308, 480, 470)\n",
      "Detected face: (267, 238, 449, 420)\n",
      "Detected: Quân Phan, Box: (267, 238, 449, 420)\n",
      "Detected face: (256, 214, 450, 408)\n",
      "Detected: Quân Phan, Box: (256, 214, 450, 408)\n",
      "Detected face: (265, 215, 466, 416)\n",
      "Detected: Quân Phan, Box: (265, 215, 466, 416)\n",
      "Detected face: (265, 214, 468, 417)\n",
      "Detected: Quân Phan, Box: (265, 214, 468, 417)\n",
      "Detected face: (263, 211, 465, 413)\n",
      "Detected: Quân Phan, Box: (263, 211, 465, 413)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import onnxruntime as ort\n",
    "import os\n",
    "\n",
    "# Hàm phát hiện khuôn mặt sử dụng Haar Cascade\n",
    "def detect_faces_haar(image, cascade_classifier, scale_factor=1.1, min_neighbors=5):\n",
    "    # Chuyển ảnh sang grayscale (yêu cầu của Haar Cascade)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Phát hiện khuôn mặt\n",
    "    faces = cascade_classifier.detectMultiScale(\n",
    "        gray,\n",
    "        scaleFactor=scale_factor,  # Tỷ lệ thu nhỏ mỗi lần quét\n",
    "        minNeighbors=min_neighbors,  # Số lượng hàng xóm tối thiểu\n",
    "        minSize=(30, 30)  # Kích thước tối thiểu của khuôn mặt\n",
    "    )\n",
    "    \n",
    "    boxes = []\n",
    "    for (x, y, w, h) in faces:\n",
    "        x1, y1 = x, y\n",
    "        x2, y2 = x + w, y + h\n",
    "        boxes.append((x1, y1, x2, y2))\n",
    "        print(f\"Detected face: ({x1}, {y1}, {x2}, {y2})\")\n",
    "    \n",
    "    return boxes\n",
    "\n",
    "# Danh sách nhãn\n",
    "class_names = ['Đẳng Cửu Dương', 'Hoàng Manh Tường', 'Quân Phan', 'Trịnh Hửu Thọ']\n",
    "\n",
    "# 1. Load Haar Cascade Classifier\n",
    "cascade_path = cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'\n",
    "if not os.path.exists(cascade_path):\n",
    "    raise FileNotFoundError(f\"Haar Cascade file not found: {cascade_path}\")\n",
    "face_cascade = cv2.CascadeClassifier(cascade_path)\n",
    "if face_cascade.empty():\n",
    "    raise ValueError(\"Failed to load Haar Cascade classifier\")\n",
    "\n",
    "# 2. Load VGG16 classifier\n",
    "classifier_path = r\"F:\\Study\\Projects\\HK6\\XLA\\Project\\FaceDetection\\vgg_face_final.onnx\"\n",
    "if not os.path.exists(classifier_path):\n",
    "    raise FileNotFoundError(f\"ONNX file not found: {classifier_path}\")\n",
    "face_classifier = ort.InferenceSession(classifier_path)\n",
    "\n",
    "# 3. Khởi tạo camera\n",
    "cap = cv2.VideoCapture(0)  # 0 là camera mặc định\n",
    "if not cap.isOpened():\n",
    "    raise ValueError(\"Cannot open camera\")\n",
    "\n",
    "try:\n",
    "    # 4. Vòng lặp xử lý khung hình từ camera\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to grab frame\")\n",
    "            break\n",
    "\n",
    "        # Resize khung hình nếu quá lớn\n",
    "        max_size = 1280\n",
    "        if max(frame.shape[:2]) > max_size:\n",
    "            scale = max_size / max(frame.shape[:2])\n",
    "            frame = cv2.resize(frame, (int(frame.shape[1] * scale), int(frame.shape[0] * scale)))\n",
    "\n",
    "        # Phát hiện khuôn mặt bằng Haar Cascade\n",
    "        boxes = detect_faces_haar(frame, face_cascade, scale_factor=1.1, min_neighbors=5)\n",
    "\n",
    "        # Lặp qua các bounding box và nhận diện\n",
    "        for box in boxes:\n",
    "            x1, y1, x2, y2 = box\n",
    "            face_crop = frame[y1:y2, x1:x2]\n",
    "            if face_crop.size == 0 or face_crop.shape[0] < 10 or face_crop.shape[1] < 10:\n",
    "                print(\"Skipping small face region\")\n",
    "                continue  # Bỏ qua vùng mặt quá nhỏ\n",
    "\n",
    "            # Chuẩn bị ảnh cho phân loại\n",
    "            face_crop = cv2.resize(face_crop, (224, 224))\n",
    "            face_crop = face_crop[:, :, ::-1]  # BGR -> RGB\n",
    "            face_crop = face_crop.astype(np.float32) / 255.0\n",
    "            face_crop = np.expand_dims(face_crop, axis=0)\n",
    "\n",
    "            # Phân loại khuôn mặt\n",
    "            inputs = {face_classifier.get_inputs()[0].name: face_crop}\n",
    "            preds = face_classifier.run(None, inputs)[0]\n",
    "            label_id = np.argmax(preds)\n",
    "            label_name = class_names[label_id]\n",
    "            print(f\"Detected: {label_name}, Box: ({x1}, {y1}, {x2}, {y2})\")\n",
    "\n",
    "            # Vẽ bounding box và nhãn\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, label_name, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "\n",
    "        # Hiển thị khung hình\n",
    "        cv2.imshow(\"Face Recognition\", frame)\n",
    "\n",
    "        # Thoát khi nhấn phím 'q'\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n",
    "finally:\n",
    "    # Giải phóng tài nguyên\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad024e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
